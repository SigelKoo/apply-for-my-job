# 生成分布式ID的方法

- 数据库自增ID
- 数据库水平拆分，设置初始值和相同的自增步长
- 批量申请自增ID
- UUID生成
- Redis的方式
- 雪花算法

## 数据库自增ID

在创建表的时候，指定主键auto_increment（自增）便可以实现

## 数据库水平拆分，设置初始值和相同的自增步长

「数据库水平拆分，设置初始值和相同的自增步长」是指在DB集群的环境下，将数据库进行水平划分，然后每个数据库设置「不同的初始值」和「相同的步长」，这样就能避免ID重复的情况

![1.png](http://dockone.io/uploads/article/20200720/415a500527a3c64743dca3d628f89961.png)

```
set @@auto_increment_offset = 1;     // 设置初始值
set @@auto_increment_increment = 2;  // 设置步长
```

扩容的情况是这种方法的一个缺点，上面我说的步长一般设置为数据库的数量，这是在确保后期不会扩容的情况下，若是确定后期会有扩容情况，在前期设计的的时候可以将步长设置长一点，「预留一些初始值给后续扩容使用」。

总之，这种方案还是优缺点的，缺点就是：「后期可能会面对无ID初始值可分的窘境，数据库总归是数据库，抗高并发也是有限的」。

## 批量申请自增ID

「批量申请自增ID」的解决方案可以解决无ID可分的问题，它的原理就是一次性给对应的数据库上分配一批的ID值进行消费，使用完了，再回来申请。

![2.png](http://dockone.io/uploads/article/20200720/bd156d3ade33cb0c6512b93ee634d075.png)

在设计的初始阶段可以设计一个有初始值字段，并有步长字段的表，当每次要申请批量ID的时候，就可以去该表中申请，每次申请后「初始值=上一次的初始值+步长」。

这样就能保持初始值是每一个申请的ID的最大值，避免了ID的重复，并且每次都会有ID使用，一次就会生成一批的id来使用，这样访问数据库的次数大大减少。

## UUID生成

UUID的核心思想是使用「机器的网卡、当地时间、一个随机数」来生成UUID。

使用UUID的方式只需要调用UUID.randomUUID().toString()就可以生成，这种方式方便简单，本地生成，不会消耗网络。

当时简单的东西，出现的问题就会越多，不利于存储，16字节128位，通常是以36位长度的字符串表示，很多的场景都不适合。

可以通过「当前的时间戳及机器mac地址」来生成，可以确保生成的UUID全球唯一。

## Redis的方式

Redis本身有incr和increby这样自增的命令，保证原子性，生成的ID也是有序的。

## 雪花算法

![3.png](http://dockone.io/uploads/article/20200720/2a152ac58344b739eb09671be7872e87.png)

第一位作为标识位，占用1bit，其值始终是0，没有实际作用。 

41bit是时间戳，毫秒级位单位，注意这里的时间戳并不是指当前时间的时间戳，而是值之间差（「当前时间-开始时间」）。开始时间一般是指ID生成器的开始时间，是由我们程序自己指定的。

后面的10bit：包括5位的「数据中心标识ID（datacenterId）和5位的机器标识ID（workerId）」，可以最多标识1024个节点（1<<10=1024）。

最后12位是序列号，12位的计数顺序支持每个节点每毫秒差生4096序列号（1<<12=4096）。

雪花算法使用数据中心ID和机器ID作为标识，不会产生ID的重复，并且是在本地生成，不会消耗网络，效率高，有数据显示，每秒能生成26万个ID。

雪花算法的计算依赖于时间，若是系统时间回拨，就会产生重复ID的情况。在雪花算法的实现中，若是其前置的时间等于当前的时间，就抛出异常，也可以关闭掉时间回拨。

# Redis如何实现分布式锁？

- 当在分布式模型下，数据只有一份（或有限制），此时需要利用锁的技术控制某一时刻修改数据的进程数。
- 与单机模式下的锁不仅需要保证进程可见，还需要考虑进程与锁之间的网络问题。（我觉得分布式情况下之所以问题变得复杂，主要就是需要考虑到**网络的延时和不可靠**。。。一个大坑）
- 分布式锁还是可以将标记存在内存，只是该内存不是某个进程分配的内存而是公共内存如 Redis、Memcache。至于利用数据库、文件等做锁与单机的实现是一样的，只要保证标记能互斥就行。

## 基于 redis 的 setnx()、expire() 方法做分布式锁

### setnx()

setnx 的含义就是 SET if Not Exists，其主要有两个参数 setnx(key, value)。该方法是原子的，如果 key 不存在，则设置当前 key 成功，返回 1；如果当前 key 已经存在，则设置当前 key 失败，返回 0。

### expire()

expire 设置过期时间，要注意的是 setnx 命令不能设置 key 的超时时间，只能通过 expire() 来对 key 设置。

### 使用步骤

1. setnx(lockkey, 1) 如果返回 0，则说明占位失败；如果返回 1，则说明占位成功

2. expire() 命令对 lockkey 设置超时时间，为的是避免死锁问题。

3. 执行完业务代码后，可以通过 delete 命令删除 key。

这个方案其实是可以解决日常工作中的需求的，但从技术方案的探讨上来说，可能还有一些可以完善的地方。**比如，如果在第一步 setnx 执行成功后，在 expire() 命令执行成功前，发生了宕机的现象，那么就依然会出现死锁的问题，所以如果要对其进行完善的话，可以使用 redis 的 setnx()、get() 和 getset() 方法来实现分布式锁。**

## 基于 redis 的 setnx()、get()、getset()方法做分布式锁

### getset()

这个命令主要有两个参数 getset(key，newValue)。该方法是原子的，对 key 设置 newValue 这个值，并且返回 key 原来的旧值。假设 key 原来是不存在的，那么多次执行这个命令，会出现下边的效果：

1. getset(key, "value1") 返回 null 此时 key 的值会被设置为 value1
2. getset(key, "value2") 返回 value1 此时 key 的值会被设置为 value2
3. 依次类推！

### 使用步骤

1. setnx(lockkey, 当前时间+过期超时时间)，如果返回 1，则获取锁成功；如果返回 0 则没有获取到锁，转向 2。
2. get(lockkey) 获取值 oldExpireTime ，并将这个 value 值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取，转向 3。
3. 计算 newExpireTime = 当前时间+过期超时时间，然后 getset(lockkey, newExpireTime) 会返回当前 lockkey 的值currentExpireTime。
4. 判断 currentExpireTime 与 oldExpireTime 是否相等，如果相等，说明当前 getset 设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试。
5. 在获取到锁之后，当前线程可以开始自己的业务处理，当处理完毕后，比较自己的处理时间和对于锁设置的超时时间，如果小于锁设置的超时时间，则直接执行 delete 释放锁；如果大于锁设置的超时时间，则不需要再对锁进行处理。
