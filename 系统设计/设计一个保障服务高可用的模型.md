# 高可用

通常是指，通过设计减少系统不能提供服务的时间。而服务器的可用性是指单位时间内（通常一年），服务器可以正常工作的时间比例。

**可用性=平均故障间隔/（平均故障间隔 + 故障恢复平均时间）**

![img](https://pic2.zhimg.com/80/v2-e687aabf2509fd43c71f6d6dcd65280d_720w.jpg)

# 如何设计系统的高可用

想要高可用就要避免使用单点，你想想看你的单台服务器再强应用优化的再极致，只要它宕机，就啥都凉凉了，所以需要多台机器也就是需要集群，方法论中叫冗余。只是有了集群是不能完全满足复杂业务的高可用的，我们要让系统在当前节点宕机的情况下，自己进行切换到好的节点去，这即所谓的故障转移。所以我们现在设计高可用系统的目标明确了，

那就是：**冗余 + 故障转移**

![img](https://pic2.zhimg.com/80/v2-8254b73959a1270a38754dee360ddf4d_720w.jpg)

1. 从客户端到反向代理Nginx这块，这个1台nginx是会可能发生故障的，所以这里可以再冗余一台Nginx，可以利用linux的 keeplived 进行探测可用性，当一台Nginx挂了之后，责会自动转移到另一台Nginx机器上来，从而保证高可用。

![img](https://pic1.zhimg.com/80/v2-b4b175e27762909e8a89d4dbf87d3adc_720w.jpg)

2. 从反向代理到后端服务service这块，反向代理这块，目前最受欢迎的是nginx，性能方面表现也很好，nginx能够自动探测后端服务的可用性，只需在nginx,config配置多台后端服务就行了。

![img](https://pic3.zhimg.com/80/v2-444cd6bc84411bc664af0506b3ce7faa_720w.jpg)

3. 从后端服务到缓存这块，缓存这块推荐使用redis主从同步方案来达到高可用，redis主从同步加上sentine哨兵机制来自动探活redis实例。

![img](https://pic3.zhimg.com/80/v2-18dca743412dc01a7492b917ae6745c2_720w.jpg)

4. 从后端服务到写数据库这块，这里可以采用双主机制，一台给线上使用，另一台冗余，当线上那台挂了才会阶梯过来使用写功能，同样是通过linux的keepalived进行自动探活。

![img](https://pic3.zhimg.com/80/v2-85a086622cf40c2ee5812c1514e24ae2_720w.jpg)

5. 从后端服务到读数据库这块，这里同样是将读库部署多台，例如部署2台，通过代码段增加连接池组件进行路由读库和探活

![img](https://pic1.zhimg.com/80/v2-935514642a27e22889f352228639bf78_720w.jpg)

## 系统高可用延伸思路

**超时机制**

在我们系统中其实大部分会调用三方接口，而这个三方接口一般是合作公司的或者是公司其他部门提供的，我们并不清楚对方接口的性能情况，有些接口在并发稍大一点的情况下会出现返回很慢，一直占用当前资源，使得我们大量的请求阻塞等。所以这块我们需要对此进行设置合理的超时时间，来快速结束这些慢请求，来保证我们系统的可用性。

我们线上就有一个业务发生过类似的事情，对方接口在我们一定并发的时候经常很慢很慢才会出现结果，最后造成我们OOM，最终发现是这个业务程序员没有合理设置超时时间造成的。

那么这个超时时间应该设置多少呢，这个并不是绝对的，需要我们根据自己的业务以及接口情况加上多次分析线上时间，来合理设置，可以不停的对其设置直到业务愉快的进行。

**降级**

降级也是互联网中老生常谈的话题，那么我们使用降级方案如何来保证系统的可用性呢，分析自己的业务，在面对流量剧增的时候，例如，秒杀，大促等这些剧增的大流量，可以将不影响本次业务的流程也砍掉，不去调用了，直接走核心业务。其实各大电商都是采取这种方案来保证系统的可用性的。

**限流**

限流是，本来我系统只能抗住10万并发，然后现在我们运营搞了什么牛逼的大促，搞的来了10倍的流量，那么系统就把瞬间不能处理的流量给截断，直接返回给用户，用户可以待会儿再试。所以限流就是为了保证系统的高可用而限制住大流量的情况发生。

# 服务器的高可用

 “高可用性”（High Availability）通常来描述一个系统经过专门的设计，从而减少停工时间，而保持其服务的高度可用性。所以当我们一说到高可用，我们满脑子都是以负载均衡为主心骨搭建的拓扑图，以他为中心，从单节点拓展为多节点，消灭单点故障。但随着我们业务架构越来越庞大复杂，那么要考虑的就不再只是服务器维度的高可用了。接下来，我来给大家介绍一下不同维度的“高可用”在架构上是如何实现的。

## 通用高可用

很多人在搭建业务的时候喜欢用一台高性能服务器搭建所有业务所需的应用和环境。比如服务器上搭建Nginx、会员系统、订单系统、自建数据库等等。这类搭建的初衷大概有简单省事、预算不足、初期业务量小感觉够用等因素。
这些困难业主要集中在业务上线初期，都是很现实的问题，不过随之带来的是更加现实的困难。性能瓶颈很快到来，后期调整架构会因越来越大的数据量和停服带来收益减少等等问题。
所以业务初期搭建一个基础高可用框架，日后根据需要逐渐添加功能。
![1](https://yqfile.alicdn.com/5ddb148031cee39cb3c112aa0e485d4a24c83320.png)

A、后期业务增加后我们再根据需要逐步扩容，例如数据库读写压力大了，我们用Redis、数据库读写分离等手段。这样扩容不用复杂的操作，不用长时间的停服迁移重要的数据信息。
![2](https://yqfile.alicdn.com/64d3c349e3be475e837f64463905ef47bb0a8073.png)

B、再后来业务量进一步扩大，需要短信服务、需要组网、需要安全防护等等，都可以灵活拓展。所以对于服务器层面来说，一开始就搭建一个高可用架构是至关重要的。

## 进阶高可用

容灾方面：
通常对于一个普通的APP、门户网站、内部系统等等业务，通用高可用已经足够了。但为了实现客户们日益提高的对体验感的的高要求，工程师们不知踏平了多少坑以后实践出了与之对应的高级高可用架构。这种架构不再针对某一个业务集群做高可用，而是以业务为维度。举个例子当某一个地域的业务不可用时，能有其他地域的备用集群顶上。

![3](https://yqfile.alicdn.com/30d6434a064b8fa7e9f42d53d7a0eaf2adcce67d.png)

![4](https://yqfile.alicdn.com/c69349a09f7f571d9d67a7dc9764b96d059120dd.png)

客户体验感：
当业务做大到一定程度，客户群体就不仅仅局限于一个市或者一个省，乃至一个国家。这时候，因为客户离业务集群太远，导致通讯质量不佳，延迟、丢包问题层出不穷。以前我们经常用“三秒”来定义一个网站的好坏，但现在主流网站大多均已采用“1.5秒”来打分了。传统的单业务节点越来越难满足了，那就得考虑多节点同时运行承载业务，可通过全局流量来实现。而多节点之间的数据同步可以用阿里云的云企业网来实现。

负载均衡从其应用的地理结构上分为本地负载均衡和全局负载均衡。本地负载均衡是指对同地域的服务器群做负载均衡，全局负载均衡是指对分别部署在不同地域有不同网络结构的服务器群做负载均衡。
• 多线路智能化解析服务
全局流量管理利用DNS智能解析和应用服务的运行状态健康检查，将用户访问定向到最合适的IP地址，使访问用户获得最快捷、最流畅的体验。
• 跨地域容灾
全局流量支持将不同地域的IP地址添加到不同的地址池，并配置健康检查。在访问策略配置中，设置默认地址池为地址池甲，Failover地址池为地址池乙，即可以实现应用服务主备IP容灾切换。
• 不同地域访问加速
使用全局流量管理，可以使不同地域的用户访问不同的IP地址池，实现用户分组管理，分组接入，帮助应用服务提高用户访问体验。

![5](https://yqfile.alicdn.com/4ffb23dc6664720e8d75290242135d4a3063e72b.png)

这样我们也就能搭建一个便于客户就近访问的业务集群了，而用CEN组网打通各机房VPC，数据同步方面的工作也能变得更简单。