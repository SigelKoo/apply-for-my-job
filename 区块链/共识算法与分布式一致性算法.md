# 共识算法

共识是在保持去中心化的同时使整个系统达成一个共同状态的能力。

### PoW https://ethfans.org/posts/the-anatomy-of-proof-of-workzx

工作量证明，组织算力解决一个哈希问题，算力越强，对哈希计算越快，获得代币的机会就越多。

###### 优点

1. 机制本身当然很复杂，有很多细节，比如：挖矿难度自动调整、区块奖励逐步减半等，这些因素都是基于经济学原理，能吸引和鼓励更多人参与。
2. 理想状态，这种机制，可以吸引很多用户参与其中，特别是越先参与的获得越多，会促使加密货币的初始阶段发展迅速，节点网络迅速扩大。在CPU挖矿的时代，比特币吸引了很多人参与“挖矿”，就是很好的证明。
3. 通过“挖矿”的方式发行新币，把比特币分散给个人，实现了相对公平。

###### 缺点

1. 算力是计算机硬件提供的，要耗费电力，是对能源的直接消耗，与人类追求节能、清洁、环保的理念相悖。不过，如果非要给“加密货币”找寻“货币价值”的意义，那么这个方面，应该是最有力的证据。
2. 这种机制发展到今天，算力的提供已经不再是单纯的CPU了，而是逐步发展到GPU、FPGA，乃至ASIC矿机。用户也从个人挖矿发展到大的矿池、矿场，算力集中越来越明显。这与去中心化的方向背道而驰，渐行渐远，网络的安全逐渐受到威胁。
3. 以太坊出块奖励不断减少，当挖矿的成本高于挖矿收益时，人们挖矿的积极性降低，会有大量算力减少，比特币网络的安全性进一步堪忧。

### PoS https://ethfans.org/posts/Proof-of-Stake-FAQ-new-2018-3-15 ### 

根据你持有货币的量和时间进行利息分配的制度。POS机制最核心的逻辑就是——谁持有币，谁就有网络的控制权。在POS机制中，仍然存在算力挖矿，需要算力解决一个数学难题。但数学难题的难度和持币者的“币龄”相关。简单来说，持币者持有币的时间越长，难题越简单，挖到币的概率越大。

###### 优点

1. 节能。不用挖矿，不需要大量耗费电力和能源。
2. 更去中心化。首先说，去中心化是相对的。相对于比特币等PoW类型的加密货币，PoS机制的加密货币对计算机硬件基本上没有过高要求，人人可挖矿（获得利息），不用担心算力集中导致中心化的出现（单用户通过购买获得51%的货币量，成本更高），网络更加安全有保障。
3. 避免紧缩。PoW机制的加密货币，因为用户丢失等各种原因，可能导致通货紧缩，但是PoS机制的加密货币按一定的年利率新增货币，可以有效避免紧缩出现，保持基本稳定。比特币之后，很多新币采用PoS机制，很多采用工作量证明机制的老币，也纷纷修改协议，“硬分叉”升级为PoS机制。

###### 缺点

1. 纯PoS机制的加密货币，只能通过IPO的方式发行，这就导致“少数人”（通常是开发者）获得大量成本极低的加密货币，在利益面前，很难保证他们不会大量抛售。
2. PoS机制的加密货币，信用基础不够牢固。
3. 为解决这个问题，很多采用PoW+PoS的双重机制，通过PoW挖矿发行加密货币，使用PoS维护网络稳定。或者采用DPoS机制，通过社区选举的方式，增强信任。

## PBFT https://www.jianshu.com/p/2383c7841d41

> 拜占庭将军问题是一个协议问题，拜占庭帝国军队的将军们必须全体一致的决定是否攻击某一支敌军。问题是这些将军在地理上是分隔开来的，并且将军中存在叛徒。叛徒可以任意行动以达到以下目标：欺骗某些将军采取进攻行动；促成一个不是所有将军都同意的决定，如当将军们不希望进攻时促成进攻行动；或者迷惑某些将军，使他们无法做出决定。如果叛徒达到了这些目的之一，则任何攻击行动的结果都是注定要失败的，只有完全达成一致的努力才能获得胜利。

这一问题是一种对现实世界的模型化，尤指网络当中由于软硬件错误、网络阻塞及恶意攻击导致的各种未知行为。

显然，在此处默认了将军们在达成一致的过程中正确的传递出了自己的决定，也就是说叛徒只存在于将军当中，不存在于传令兵当中。故要让拜占庭将军问题有解，必须要具备一个重要前提，即信道必须是安全可靠的。关于信道可靠问题，会引出两军问题。两军问题的结论是，在一个不可靠的通信链路上试图通过通信以达成一致是基本不可能或者十分困难的。

### 拜占庭容错

拜占庭将军问题提出后，有很多的算法被提出用于解决这个问题。这类算法统称拜占庭容错算法（BFT: Byzantine Fault Tolerance）。简略来说，拜占庭容错（BFT）不是某一个具体算法，而是能够抵抗拜占庭将军问题导致的一系列失利的系统特点。 这意味着即使某些节点出现缺点或恶意行为，拜占庭容错系统也能够继续运转。本质上来说，拜占庭容错方案就是少数服从多数。

拜占庭将军问题的原始论文给出了一些解决思路，但其更注重理论上的可行性。算法效率不高，算法复杂度为指数级，且文中明确指出时间成本及消息传递数量很大。因此不具备太大的实用价值。

拜占庭容错系统需要达成如下两个指标：

- **安全性：**任何已经完成的请求都不会被更改，它可以在以后请求看到。在区块链系统中，可以理解为，已经生成的账本不可篡改，并且可以被节点随时查看。
- **活性：**可以接受并且执行非拜占庭客户端的请求，不会被任何因素影响而导致非拜占庭客户端的请求不能执行。在区块链系统中，可以理解为，系统需要持续生成区块，为用户记账，这主要靠挖矿的激励机制来保证。

拜占庭系统目前普遍采用的假设条件包括:

- 拜占庭节点的行为可以是任意的，拜占庭节点之间可以共谋；
- 节点之间的错误是不相关的；
- 节点之间通过异步网络连接，网络中的消息可能丢失、乱序、延时到达；
- 服务器之间传递的信息,第三方可以知晓 ,但是不能篡改、伪造信息的内容和验证信息的完整性；

#### 实用拜占庭容错

> PBFT(Practical Byzantine Fault Tolerance)算法由麻省理工学院的Miguel Castro 和Barbara Liskov于1999年提出，解决了原始拜占庭容错算法效率不高的问题，将算法复杂度由指数级降低到多项式级，使得拜占庭容错算法在实际系统应用中变得可行。

PBFT是联盟币的共识算法的基础。实现了在有限个节点的情况下的拜占庭问题，有3f + 1的容错性（拜占庭将军问题也只在节点数N > 3f时可解），并同时保证一定的性能。其采用了密码学相关技术(RSA 签名算法、消息验证编码和摘要)确保消息传递过程无法被篡改和破坏。

拜占庭将军问题在节点数N > 3f时有解的正确性证明比较复杂，此处仅举一个简单例子说明。

在恶意节点数f = 1，节点数N = 3f = 3时，可以看到，发令者和接令者任意角色出现叛徒都会导致其他节点无法作出决定。

![img](https://pic1.zhimg.com/80/v2-0f8bb176d4dbe60d1767d143b49fed8c_720w.jpg)

而当节点数N>3f（如4个）时，无论哪个角色出现叛徒，最终其他节点总能根据少数服从多数的原则达成共识。

![img](https://pic4.zhimg.com/80/v2-b997807734fcb93b03f798265e9a81db_720w.jpg)

![img](https://pic3.zhimg.com/80/v2-a6d90d184c7454bff552ae3709e7b1ee_720w.jpg)

**为什么PBFT算法最大容错节点数量f是(N-1)/3？**

假定节点总数是N，作恶节点数为f，那么剩下的正确节点数为N - f，意味着只要收到N - f个消息且N - f > f就能做出决定，但是这N - f个消息有可能有f个是由作恶节点冒充的（或因网络延迟导致f个恶意节点的消息先被收到），那么正确的消息就是N - f - f个，为了多数一致，正确消息必须占多数，也就是N - f - f > f ，所以N最少是3f + 1个。

#### PBFT算法流程

涉及角色：主节点、普通节点

在PBFT原始论文中，存在副本节点（replica）和备份节点（backup）两种称谓。其中，副本节点一般包括主节点在内，备份节点则不包括，而两种称谓又相当容易混淆，因此本文将备份节点称为普通节点。

每个主节点的工作过程称为一个视图（view），用v表示视图编号

主节点由普通节点轮流当选，具体计算过程为主节点p = v mod |R|（|R|为节点个数）

**主节点的作用：**

正常工作时，接收客户端的事务请求，验证request身份后，为该请求设置编号，广播pre-prepare消息

新主节点当选时，根据自己收集的View-Change消息，发送View-New信息，让其它节点同步数据

主节点与所有的其它节点维系心跳

如果主节点宕机，会因为心跳超时，而触发重新选举，保证系统运行稳定

如果主节点恶意发送错误编号的消息，那么会在后续的操作中，被副本节点察觉，因为 prepare和commit阶段都是会进行广播的，一旦不一致，触发view-change

如果主节点不发送接收到的request，客户端在超时未回复时，会重发request到所有的副本节点，并触发view-change

如果主节点节点篡改消息，因为有Request里面有数据和客户端的签名，所以primary无法篡改消息，其它副本会先验证消息的合法性，否则丢弃，并触发view-change

综上所述，限制了权限的主节点，如果宕机、或者不发生消息、或者发送错误编号的消息、或者篡改消息，都会被其它节点感知，并触发view-change。

**（1）Request**

客户端C向主节点p发送<REQUEST, o, t, c>

o：请求的具体操作

t：请求时客户端追加的时间戳

c：客户端标识

REQUEST: 包含消息内容m，以及消息摘要d(m)。

客户端对请求进行签名。

**（2）Pre-Prepare**

主节点收到客户端的请求，需要对客户端请求消息签名是否正确进行校验。

非法请求则丢弃。正确请求则分配一个编号n，编号n主要用于对客户端的请求进行排序。然后广播一条<<PRE-PREPARE, v, n, d>, m>消息给其它普通节点。

v：视图编号

d：客户端消息摘要

m：消息内容

主节点对<PRE-PREPARE, v, n, d>进行签名。

**（3）Prepare**

普通节点i收到主节点的Pre-Prepare消息，需要满足以下条件方可接受消息：

A、请求和预准备消息的签名正确，并且d与m的摘要一致。

B、当前视图编号是v。

C、该普通节点从未在视图v中接受过序号为n但是摘要d不同的消息m。

D、预准备消息的序号n在区间[h, H]内。

非法请求则丢弃。正确请求则普通节点i进入准备状态并向所有其它节点（包括主节点）发送一条<PREPARE, v, n, d, i>消息, v, n, d, m与上述Pre-Prepare消息内容相同，i是当前副本节点编号。

普通节点i对<PREPARE, v, n, d, i>签名。记录Pre-Prepare和Prepare消息到日志中，用于视图轮换过程中恢复未完成的请求操作。

Prepare阶段如果发生视图轮换会导致丢弃Prepare阶段的请求。

**（4）Commit**

主节点和普通节点收到PREPARE消息，需要满足以下条件方可接受消息：

A、普通节点对Prepare消息的签名正确。

B、消息的视图编号v与节点的当前视图编号一致。

C、n是否在区间[h, H]内。

非法请求则丢弃。如果节点i收到了2f+1个（包括自身在内）验证通过的Prepare消息，表明网络中的大多数节点已经收到同意信息，则向其它节点包括主节点发送一条<COMMIT, v, n, d, i>消息，v, n, d, i与上述PREPARE消息内容相同。

节点i对<COMMIT, v, n, d, i>签名。记录Commit消息到日志中，用于视图轮换过程中恢复未完成的请求操作。记录其它副本节点发送的Prepare消息到日志中。Commit阶段用来确保网络中大多数节点都已经收到足够多的信息来达成共识，如果Commit阶段发生视图轮换，会保存原来Commit阶段的请求，不会达不成共识，也不会丢失请求编号。

**（5）Reply**

主节点和普通节点收到Commit消息，需要满足以下条件方可接受消息：

A、节点对Commit消息的签名正确。

B、消息的视图编号v与节点的当前视图编号一致。

C、n是否在区间[h, H]内。

非法请求则丢弃。如果副本节点i收到了2f+1个（包括自身在内）验证通过的Commit消息，说明当前网络中的大部分节点已经达成共识，运行客户端的请求操作o，并返回<REPLY, v, t, c, i, r>给客户端，

r：是请求操作结果，客户端如果收到f+1个相同的REPLY消息，说明客户端发起的请求已经达成全网共识，否则客户端需要判断是否重新发送请求给主节点。记录其它副本节点发送的Commit消息到日志中。

### DPoS

DPoS是一种基于投票选举的共识算法，有点像民主大会，持币人选出几个代表节点来运营网络，用专业运行的网络服务器来保证区块链网络的安全和性能。

DPoS机制中，不需要算力解决数学难题，而是由持币者选出谁说生产者，如果生产者不称职，就有随时有可能被投票出局，这也就解决了POS的性能问题。

1. 随机指定生产者出场顺序；
2. 不按顺序生产的区块无效；
3. 每过一个周期洗牌一次，打乱原有顺序；
4. DPOS允许所有矿池每三秒钟轮换一次，并且其他人已被安排在后续进程中，于是，没有人可以在预设位置外生产区块。如果一个块生产者这么做了，就可能被投票出局。

###### 优点

1. 能耗更低。DPoS机制将节点数量进一步减少到101个，在保证网络安全的前提下，整个网络的能耗进一步降低，网络运行成本最低。
2. 更加去中心化。目前，对于比特币而言，个人挖矿已经不现实了，比特币的算力都集中在几个大的矿池手里，每个矿池都是中心化的，就像DPoS的一个受托人，因此DPoS机制的加密货币更加去中心化。PoS机制的加密货币（比如未来币），要求用户开着客户端，事实上用户并不会天天开着电脑，因此真正的网络节点是由几个股东保持的，去中心化程度也不能与DPoS机制的加密货币相比。
3. 更快的确认速度。每个块的时间为10秒，一笔交易（在得到6-10个确认后）大概1分钟，一个完整的101个块的周期大概仅仅需要16分钟。相比比特币更快。以太坊（PoW机制）产生一个区块需要12秒，一笔交易完成（12个区块确认后）需要约3分钟。点点币（PoS机制）确认一笔交易大概也需要1小时。

###### 缺点

1. 投票的积极性并不高。绝大多数持股人（90％+）从未参与投票。这是因为投票需要时间、精力以及技能，而这恰恰是大多数投资者所缺乏的。
2. 对于坏节点的处理存在诸多困难。社区选举不能及时有效的阻止一些破坏节点的出现，给网络造成安全隐患。

### PoA

授权证明（PoA）是PoS一致性算法的子集，交易有效性最终由一组经批准的链上账户确定，称为“授权节点”。确定授权节点的标准是通过网络治理结构中编写的方法确定性地决定的。

PoA共识依赖于验证者的声誉和过去的表现。这个想法是验证者节点将其身份/声誉放到我的身上。私人联盟网络的一个重要方面是链上地址与已知的现实世界身份之间的联系。因此，我们可以说验证节点正在盯着他们的“身份”或“声誉”（而不是他们的经济持有）。这为验证者创建了一定程度的问责制，最适合企业，私有或测试网络。

# 分布一致性算法

传统分布式一致性研究大多不考虑拜占庭容错问题，即假设不存在恶意篡改和伪造数据的节点。区块链系统的共识算法则必须运行于更为复杂、开放和缺乏信任的环境下，相较于传统环境，节点数量更多且可能存在恶意节点。

## 状态机复制

状态机是有限状态自动机的简称，是现实事物运行规则抽象而成的一个数学模型。

我们通常所说的状态机是有限状态机，也就是被描述的事物的状态的数量是有限个，例如自动门的状态就是两个 open 和 closed 。

状态机的全称是有限状态自动机，自动两个字也是包含重要含义的。给定一个状态机，同时给定它的当前状态以及输入，那么输出状态时可以明确的运算出来的。例如对于自动门，给定初始状态 closed ，给定输入“开门”，那么下一个状态时可以运算出来的。

#### 状态机四大概念

下面来给出状态机的四大概念

第一个是 State ，状态。一个状态机至少要包含两个状态。例如上面自动门的例子，有 open 和 closed 两个状态。

第二个是 Event ，事件。事件就是执行某个操作的触发条件或者口令。对于自动门，“按下开门按钮”就是一个事件。

第三个是 Action ，动作。事件发生以后要执行动作。例如事件是“按开门按钮”，动作是“开门”。编程的时候，一个 Action 一般就对应一个函数。

第四个是 Transition ，变换。也就是从一个状态变化为另一个状态。例如“开门过程”就是一个变换。

通过一个事件中的动作可以让一个状态变换到另一个状态。

### 复制状态机

一致性算法是在复制状态机（`Replicated State Machine`）的背景下提出来的。在这个方法中，一组 `Server` 的状态机计算相同状态的副本，并且即使有一部分 `Server` 宕机了它们仍然能够继续运行。在分布式系统中，复制状态机被用来解决各种容错问题。具有单个集群 `Leader` 的大规模系统，例如 `GFS`、`HDFS`、`RAMCloud`，一般使用一个单独的复制状态机来管理 `Leader` 选举和存储配置信息，必须能够使 `Leader` 从失败中恢复。使用复制状态机的例子包括 `Chubby`和 `ZooKeeper`。

![img](https://knowledge-sharing.gitbooks.io/raft/content/assets/Figure-1-Replicated-state-machine-architecture.png)

图：复制状态机架构。一致性算法管理来自客户端的状态机命令的复制日志。状态机处理日志中相同顺序的命令序列，因此会输出相同的结果。

如图所示，一般通过使用复制日志来实现复制状态机。每个 `Server`存储着一份包含命令序列的日志文件，状态机会按顺序执行这些命令。因为每个日志包含相同的命令，并且顺序也相同，所以每个状态机处理相同的命令序列。由于状态机是确定性的，所以处理相同的状态，得到相同的输出。

保证复制日志的一致性是一致性算法的任务。一个 `Server` 上的一致性模块会接收来自客户端的命令，并把命令添加到它的日志文件中。它同其它 `Server` 上的一致性模块进行通信，确保每一个日志最终包含相同的请求且顺序也相同，即使某些 `Server` 故障。一旦这些命令被正确复制，每个 `Server` 的状态机都会按照日志中的顺序去处理，将输出结果返回给客户端。最终，这些 `Server` 看起来就像一个单独的、高可靠的状态机。

对于实际系统，一致性算法一般具有如下特点：

- 安全。满足在所有非拜占庭条件下确保安全（从来不会返回错误结果），包括网络延迟、分区、丢包、重复和重排序。
- 高可用。只要集群中的大部分 `Server` 正常运行，并能够互相通信且可以同客户端通信，这个集群就完全可用。因此，拥有5个 Server 的集群可以容忍其中的2个 `Server` 失败。假使通过停掉某些 `Server` 使其失败，稍后它们会从持久化存储的状态进行恢复，并重新加入到集群中。
- 不依赖于时序。确保日志的一致性：时钟错误，以及极端情况下的消息延迟，在最坏的情况下都会造成可用性问题。
- 通常情况下，只要集群中大多数 `Server` 成功响应了某一轮 `RPC` 调用，一个命令就算完成。少部分较慢的 `Server` 不应该影响到整个系统性能。

## CAP

![img](https://bkimg.cdn.bcebos.com/pic/5bafa40f4bfbfbed9c15b19b72f0f736aec31f81?x-bce-process=image/watermark,image_d2F0ZXIvYmFpa2U5Mg==,g_7,xp_5,yp_5/format,f_auto)

- Consistency（一致性）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）
- Availability（可用性）：保证每个请求不管成功或者失败都有响应。
- Partition tolerance（分区容错性）：系统中任意信息的丢失或失败不会影响系统的继续运作。

### 分区容错性

![img](https://www.wangbase.com/blogimg/asset/201807/bg2018071601.png)



G1 和 G2 是两台跨区的服务器。G1 向 G2 发送一条消息，G2 可能无法收到。系统设计的时候，必须考虑到这种情况。一般来说，分区容错无法避免，因此可以认为 CAP 的 P 总是成立。CAP 定理告诉我们，剩下的 C 和 A 无法同时做到。

### 一致性

写操作之后的读操作，必须返回该值。举例来说，某条记录是 v0，用户向 G1 发起一个写操作，将其改为 v1。

![img](https://www.wangbase.com/blogimg/asset/201807/bg2018071602.png)

接下来，用户的读操作就会得到 v1。这就叫一致性。

![img](https://www.wangbase.com/blogimg/asset/201807/bg2018071603.png)

问题是，用户有可能向 G2 发起读操作，由于 G2 的值没有发生变化，因此返回的是 v0。G1 和 G2 读操作的结果不一致，这就不满足一致性了。

![img](https://www.wangbase.com/blogimg/asset/201807/bg2018071604.png)

为了让 G2 也能变为 v1，就要在 G1 写操作的时候，让 G1 向 G2 发送一条消息，要求 G2 也改成 v1。

![img](https://www.wangbase.com/blogimg/asset/201807/bg2018071605.png)

这样的话，用户向 G2 发起读操作，也能得到 v1。

![img](https://www.wangbase.com/blogimg/asset/201807/bg2018071606.png)

### 可用性

只要收到用户的请求，服务器就必须给出回应。

用户可以选择向 G1 或 G2 发起读操作。不管是哪台服务器，只要收到请求，就必须告诉用户，到底是 v0 还是 v1，否则就不满足可用性。

### 矛盾

一致性和可用性，为什么不可能同时成立？答案很简单，因为可能通信失败（即出现分区容错）。

如果保证 G2 的一致性，那么 G1 必须在写操作时，锁定 G2 的读操作和写操作。只有数据同步后，才能重新开放读写。锁定期间，G2 不能读写，没有可用性不。

如果保证 G2 的可用性，那么势必不能锁定 G2，所以一致性不成立。

综上所述，G2 无法同时做到一致性和可用性。系统设计时只能选择一个目标。如果追求一致性，那么无法保证所有节点的可用性；如果追求所有节点的可用性，那就没法做到一致性。

读者问，在什么场合，可用性高于一致性？

举例来说，发布一张网页到 CDN，多个服务器有这张网页的副本。后来发现一个错误，需要更新网页，这时只能每个服务器都更新一遍。

一般来说，网页的更新不是特别强调一致性。短时期内，一些用户拿到老版本，另一些用户拿到新版本，问题不会特别大。当然，所有人最终都会看到新版本。所以，这个场合就是可用性高于一致性。

## Paxos

paxos现在大多是应用于replication的一致性，用来实现一个多节点一致的日志。

目的：让参与分布式处理的每个参与者逐步达成一致意见。或者说，在一个选举过程中，让不同的选民最终做出一致的决定。

假想了一个叫做Paxos的希腊城邦进行选举的情景，这个算法也是因此而得名。在他的假想中，这个城邦要采用民主提议和投票的方式选出一个最终的决议，但由于城邦的居民没有人愿意把全部时间和精力放在这种事情上，所以他们只能不定时的来参加提议，不定时来了解提议、投票进展，不定时的表达自己的投票意见。Paxos算法的目标就是让他们按照少数服从多数的方式，最终达成一致意见。 

具体情况

1. 在整个提议和投票过程中，主要的角色就是“提议者”（向“接受者”提出提议）和“接受者”（收到“提议者”的提议后，向“提议者”表达自己的意见）。 
2. 第一阶段：因为存在多个“提议者”，如果都提意见，那么“接受者”接受谁的不接受谁的？太混乱了。所以，要先明确哪个“提议者”是意见领袖有权提出提议，未来，“接受者”们就主要处理这个“提议者”的提议了。
3. 第二阶段：由上阶段选出的意见领袖提出提议，“接受者”反馈意见。如果多数“接受者”接受了一个提议，那么提议就通过了。

问题

1）怎么明确意见领袖呢？通过编号。每个“提议者”在第一阶段先报个号，谁的号大，谁就是意见领袖。如果不好理解，可以想象为贿选。每个提议者先拿着钞票贿赂一圈“接受者”，谁给的钱多，第二阶段“接受者”就听谁的。（注：这里和下文提到的“意见领袖”，并不是一个新的角色，而是代表在那一轮贿赂成功的“提议者”。所以，请把意见领袖理解为贿赂中胜出的“提议者”即可）

2）有个跟选举常识不一样的地方，就是每个“提议者”不会执着于让自己的提议通过，而是每个“提议者”会执着于让提议尽快达成一致意见。所以，为了这个目标，如果“提议者”在贿选的时候，发现“接受者”已经接受过前面意见领袖的提议了，即便“提议者”贿选成功，也会默默的把自己的提议改为前面意见领袖的提议。所以一旦贿赂成功，胜出的“提议者”再提出提议，提议内容也是前面意见领袖的提议。

3）钱的多少很重要，如果钱少了，无论在第一还是第二阶段“接受者”都不会理你，直接拒绝。

4）上面2）中讲到，如果“提议者”在贿选时，发现前面已经有意见领袖的提议，那就将自己的提议默默改成前面意见领袖的提议。这里有一种情况，如果你是“提议者”，在贿赂的时候，“接受者1”跟你说“他见过的意见领袖的提议是方案1”，而“接受者2”跟你说“他见过的意见领袖提议是方案2”，你该怎么办？这时的原则也很简单，还是：钱的多少很重要！你判断一下是“接受者1”见过的意见领袖有钱，还是“接受者2”见过的意见领袖有钱？如何判断呢？因为“接受者”在被“提议者”贿赂的时候，自己会记下贿赂的金额。所以当你贿赂“接受者”时，一旦你给的贿赂多而胜出，“接受者”会告诉你两件事情：a.前任意见领袖的提议内容（如果有的话），b.前任意见领袖当时贿赂了多少钱。这样，再面对刚才的情景时，你只需要判断一下“接受者1”和“接受者2”告诉你的信息中，哪个意见领袖当时给的钱多，那你就默默的把自己的提议，改成那个意见领袖的提议。

5）最后这一部分最有意思，但描述起来有点绕，如果不能一下子就理解可以先看后面的例子。在整个选举过程中，每个人谁先来谁后到，“接受者”什么时间能够接到“提议者”的信息，是完全不可控的。所以很可能一个意见领袖已经产生了，但是由于这个意见领袖的第二阶段刚刚开始，绝大部分“接受者”还没有收到这个意见领袖的提议。结果，这时突然冲进来了一个新的土豪“提议者”，那么这个土豪“提议者”也是有机会让自己的提议胜出的！

a.上一个意见领袖要赶在土豪“提议者”贿赂到“接受者”前，赶到“接受者”面前让他接受自己的提议，否则会因为自己的之前贿赂的钱比土豪少而被拒绝。b.土豪“提议者”要赶在上一个意见领袖将提议传达给“接受者”前，贿赂到“接受者”，否则土豪“提议者”即便贿赂成功，也要默默的将自己的提议改为前任意见领袖的提议。这整个博弈的过程，最终就看这两个“提议者”谁的进展快了。但最终一定会有一个意见领袖，先得到多数“接受者”的认可，那他的提议就胜出了。

**总结**

1）Paxos算法包括两个阶段：第一个阶段主要是贿选，还没有提出提议；第二个阶段主要根据第一阶段的结果，明确接受谁的提议，并明确提议的内容是什么（这个提议可能是贿选胜出“提议者”自己的提议，也可能是前任意见领袖的提议，具体是哪个提议，见下面第3点原则）。

2）编号（贿赂金额）很重要，无论在哪个阶段，编号（贿赂金额）小的，都会被鄙视（被拒绝）。

3）在第一阶段中，一旦“接受者”已经接受了之前意见领袖的提议，那后面再来找这个“接受者”的“提议者”，即便在贿赂中胜出，也要被洗脑，默默将自己的提议改为前任意见领袖的提议，然后他会在第二阶段提出该提议（也就是之前意见领袖的提议，以力争让大家的意见趋同）。如果“接受者”之前没有接受过任何提议，那贿选胜出的“提议者”就可以提出自己的提议了。

**举例**

最后举个例子，加深一下印象：

有两个“提议者”和三个“接受者”。

1）首先“提议者1”贿赂了3个“接受者”

![img](https://pic4.zhimg.com/80/v2-7ac400cb745b36f0667391999e828d14_720w.jpg?source=1940ef5c)

2）3个“接受者”记录下贿赂金额，因为目前只有一个“提议者”出价，因此$1就是最高的了，所以“接受者”们返回贿赂成功。此外，因为没有任何先前的意见领袖提出的提议，因此“接受者”们告诉“提议者1”没有之前接受过的提议（自然也就没有上一个意见领袖的贿赂金额了）。

![img](https://pic4.zhimg.com/80/v2-8b2f4d5be0e96e808b9f5cd1bcce6c8e_720w.jpg?source=1940ef5c)

3）“提议者1”向“接受者1”提出了自己的提议：1号提议，并告知自己之前已贿赂$1。

![img](https://pic1.zhimg.com/80/v2-aec9d3006e40be28b49ba0d80e2c9a47_720w.jpg?source=1940ef5c)

4）“接受者1”检查了一下，目前记录的贿赂金额就是$1，于是接受了这一提议，并把1号提议记录在案。

![img](https://pic2.zhimg.com/80/v2-b04580b0ef8f5087fce2c636b4f925a6_720w.jpg?source=1940ef5c)

5）在“提议者1”向“接受者2”“接受者3”发起提议前，土豪“提议者2”出现，他开始用$2贿赂“接受者1”与“接受者2”。

![img](https://pic4.zhimg.com/80/v2-8efd4cd44a21d220160988c1f9a7d5ed_720w.jpg?source=1940ef5c)

6）“接受者1”与“接受者2”立刻被收买，将贿赂金额改为$2。但是，不同的是：“接受者1”告诉“提议者2”,之前我已经接受过1号提议了，同时1号提议的“提议者”贿赂过$1；而，“接受者2”告诉“提议者2”，之前没有接受过其他意见领袖的提议，也没有上一个意见领袖的贿赂金额。

![img](https://pic1.zhimg.com/80/v2-50c0841a1ee64eab377a4a01abe5d974_720w.jpg?source=1940ef5c)

7）这时，“提议者1”回过神来了，他向“接受者2”和“接受者3”发起1号提议，并带着信息“我前期已经贿赂过$1”。

![img](https://pic1.zhimg.com/80/v2-5d09580e20dff6e1e464449ee5fbec61_720w.jpg?source=1940ef5c)

8）“接受者2”“接受者3”开始答复：“接受者2”检查了一下自己记录的贿赂金额，然后表示，已经有人出价到$2了，而你之前只出到$1，不接受你的提议，再见。但“接受者3”检查了一下自己记录的贿赂金额，目前记录的贿赂金额就是$1，于是接受了这一提议，并把1号提议记录在案。

![img](https://pic1.zhimg.com/80/v2-06c42e88602406736aba0d3fcd59f67c_720w.jpg?source=1940ef5c)

9）到这里，“提议者1”已经得到两个接受者的赞同，已经得到了多数“接受者”的赞同。于是“提议者1”确定1号提议最终通过。

10）下面，回到“提议者2”。刚才说到，“提议者2”贿赂了“接受者1”和“接受者2”，被“接受者1”告知：“之前已经接受过1号提议了，同时1号提议的‘提议者’贿赂过$1”，并被“接受者2”告知：“之前没有接到过其他意见领袖的提议，也没有其他意见领袖的贿赂金额”。这时“提议者2”，拿到信息后，判断一下，目前贿赂过最高金额（即$1）的提议就是1号提议了，所以“提议者2”默默的把自己的提议改为与1号提议一致，然后开始向“接受者1”“接受者2”发起提议（提议内容仍然是1号提议），并带着信息：之前自己已贿赂过$2。

![img](https://pic4.zhimg.com/80/v2-6a1856fdc8380a8841a822ef32ed072f_720w.jpg?source=1940ef5c)

11）这时“接受者1”“接受者2”收到“提议者2”的提议后，照例先比对一下贿赂金额，比对发现“提议者2”之前已贿赂$2，并且自己记录的贿赂金额也是$2，所以接受他的提议，也就是都接受1号提议。

![img](https://pic2.zhimg.com/80/v2-32b1eabfec9a6969ba1437a0972861f6_720w.jpg?source=1940ef5c)

12）于是，“提议者2”也拿到了多数派的意见，最终通过的也是1号提议。

回到上面的第5）步，如果“提议者2”第一次先去贿赂“接受者2”“接受者3”会发生什么？那很可能1号提议就不会成为最终选出的提议。因为当“提议者2”先贿赂到了“接受者2”“接受者3”，那等“提议者1”带着议题再去找这两位的时候，就会因为之前贿赂的钱少（$1<$2）而被拒绝。所以，这也就是刚才讲到可能存在博弈的地方：a.“提议者1”要赶在“提议者2”贿赂到“接受者2”“接受者3”之前，让“接受者2”“接受者3”接受自己的意见，否则“提议者1”会因为钱少而被拒绝；b.“提议者2”要赶在“提议者1”之前贿赂到“接受者”，否则“提议者2”即便贿赂成功，也要默默的将自己的提议改为“提议者1”的提议。但你往后推演会发现，无论如何，总会有一个“提议者”的提议获得多数票而胜出。

## Raft

Paxos算法不容易实现，Raft算法是对Paxos算法的简化和改进

1. Leader领导节点，负责发出提案
2. Follower追随者节点，负责同意Leader发出的提案
3. Candidate候选人，负责争夺Leader

![img](https://pic2.zhimg.com/80/v2-b503e1b87b4888a82df87896cae29bad_720w.jpg)

步骤：Raft算法将一致性问题分解为两个的子问题，**Leader选举**和**状态复制**

### Leader选举

1. 每个Follower都持有一个**定时器**。

   ![img](https://pic2.zhimg.com/80/v2-54ff345bdee35c3b90efef4e525aea69_720w.jpg)

2. 当定时器时间到了而集群中仍然没有Leader，Follower将声明自己是Candidate并参与Leader选举，同时**将消息发给其他节点来争取他们的投票**，若其他节点长时间没有响应Candidate将重新发送选举信息。

   ![img](https://pic2.zhimg.com/80/v2-ddf8c68b3e1e57594a08f032482e8251_720w.jpg)

3. 集群中其他节点将给Candidate投票

   ![img](https://pic2.zhimg.com/80/v2-b0d887514aa22bf81a9ebdd2f03cc2dd_720w.jpg)

4. 获得多数派支持的Candidate将成为**第M任Leader**（M任是最新的任期）

   ![img](https://pic4.zhimg.com/80/v2-2bf8a06c823ad2fb38e1be20fe60b0df_720w.jpg)

5. 在任期内的Leader会**不断发送心跳**给其他节点证明自己还活着，其他节点受到心跳以后就清空自己的计时器并回复Leader的心跳。这个机制保证其他节点不会在Leader任期内参加Leader选举。

   ![img](https://pic1.zhimg.com/80/v2-bd510806788699634cab9500f6c2edfc_720w.jpg)

   ![img](https://pic3.zhimg.com/80/v2-5beebe7894d879cf1ea54f460467649e_720w.jpg)

6. 当Leader节点出现故障而导致Leader失联，没有接收到心跳的Follower节点将准备成为Candidate进入下一轮Leader选举

7. 若出现两个Candidate同时选举并获得了相同的票数，那么这两个Candidate将**随机推迟一段时间**后再向其他节点发出投票请求，这保证了再次发送投票请求以后不冲突

   ![img](https://pic3.zhimg.com/80/v2-70d1b9ad1fdb058b04ff7d5a521435be_720w.jpg)

### 状态复制

1. Leader负责接收来自Client的提案请求**（红色提案表示未确认）**

   ![img](https://pic1.zhimg.com/80/v2-a27ccc3437ed92669fa479f142176614_720w.jpg)

2. 提案内容将包含在Leader发出的**下一个心跳中**

   ![img](https://pic3.zhimg.com/80/v2-461b76641286d57534288d6b3be4dbf6_720w.jpg)

3. Follower接收到心跳以后回复Leader的心跳

   ![img](https://pic2.zhimg.com/80/v2-f5e771562f2eda04c8db30d1d8462e39_720w.jpg)

4. Leader接收到多数派Follower的回复以后**确认提案**并写入自己的存储空间中并**回复Client**

   ![img](https://pic4.zhimg.com/80/v2-3e614177fe59302ec933b629f55be2f7_720w.jpg)

5. Leader**通知Follower节点确认提案**并写入自己的存储空间，随后所有的节点都拥有相同的数据

   ![img](https://pic2.zhimg.com/80/v2-dd0d388855310707dd85b4ed6c8c5f6d_720w.jpg)

6. 若集群中出现网络异常，导致集群被分割，将出现多个Leader

   ![img](https://pic2.zhimg.com/80/v2-ad1fa60698389bc0efbe3413b2549729_720w.jpg)

7. 被分割出的非多数派集群将无法达到共识，即**脑裂**，如图中的A、B节点将无法确认提案

   ![img](https://pic1.zhimg.com/80/v2-093a8f1ea3c1ea389281036f7ee9c320_720w.jpg)

   ![img](https://pic2.zhimg.com/80/v2-e54f332371974d6124ba494fc68f6fd5_720w.jpg)

8. 当集群再次连通时，将**只听从最新任期Leader**的指挥，旧Leader将退化为Follower，如图中B节点的Leader（任期1）需要听从D节点的Leader（任期2）的指挥，此时集群重新达到一致性状态

   ![img](https://pic2.zhimg.com/80/v2-c86b7d545b291d7d07d4b47e53a334cd_720w.jpg)

   ![img](https://pic2.zhimg.com/80/v2-477365ef270e6e967fee60e64886cd6d_720w.jpg)

   

raft协议对这种情况的处理是，虽然出现了双主，但是由于老的领导者是不可能在数据复制阶段拿到大多数的确认的，所以老的领导者将不能够正常地写入数据，而新的领导者是可以正常写入数据的，当两者之间的网络恢复正常之后，老的领导者接收到了比它任期大的领导者发的消息，就会自动地转换为了跟随者，集群也就恢复了正常的状态。这里面可能出现的问题就是客户端是有可能从老的领导者分区中读取到老的数据的，这个在一般的情况下也是可以接受的。