# 从内存中访问数据的过程

总体流程：1.获得数据在内存的物理地址；2.从内存中取数据

**获取物理地址**

需要使用虚拟地址（逻辑地址）进行转化：

先查找TLB（快表：为硬件结构，保存有部分内存中页表的内容，目的是提高效率），把虚拟地址写为二进制的形式，由页面大小得到页内偏移位数，剩下的是虚拟页号，在这里虚拟页号进一步分为TLB标记和TLB组索引。由组索引和TLB标记查看有无对应的物理页号及标记位是否为”1”，若存在，把物理页号拼接页内地址得到实地址

若不存在，说明TLB不命中，查找内存中的页表。这里就相对比较单纯了，通过页号及页表寄存器找到相应的页表项，看一下有没有物理页号及有效位是否为“1”，若有，则命中，把物理页号拼接到页内地址即得到实地址；若无，则比较麻烦了，说明内存中没有要找的这个页面，产生缺页中断，需从外存调入。

**根据地址来访问数据**

先查找高速缓存Cache（内存的部分副本），在根据第一步得到的物理地址进行查找时，要了解Cache的几种映射方式，主要是直接映射方式和组相连映射方式，根据 不同的映射方式来分析上一步得到的物理地址。

一般说来，我们由Cache索引和标志位找到Cache中位置，再查看有效位是否为“1”，即Cache中是否存在要查找的内存地址中内容的副本；若为“1”，即有效，则根据偏移量（字块内地址）取出Cache单元的内容即可。如不在，则要去主存中查找对应的物理地址的内容。

# 如何减少频繁分配内存（malloc或者new）造成的内存碎片

内存池（Memory Pool）是一种内存分配方式。通常我们习惯直接使用new、malloc等API申请分配内存，这样做的缺点在于：由于所申请内存块的大小不定，当频繁使用时会造成大量的内存碎片并进而降低性能。内存池则是在真正使用内存之前，先申请分配一定数量的、大小相等（一般情况下）的内存块留作备用。当有新的内存需求时，就从内存池中分出一部分内存块，若内存块不够再继续申请新的内存。这样做的一个显著优点是尽量避免了内存碎片，使得内存分配效率得到提升。

1. 针对特殊情况，例如需要频繁分配释放固定大小的内存对象时，不需要复杂的分配算法和多线程保护。也不需要维护内存空闲表的额外开销，从而获得较高的性能。
2. 由于开辟一定数量的连续内存空间作为内存池块，因而一定程度上提高了程序局部性，提升了程序性能。
3. 比较容易控制页边界对齐和内存字节对齐，没有内存碎片的问题。
4. 当需要分配管理的内存在100M一下的时候，采用内存池会节省大量的时间，否则会耗费更多的时间。
5. 内存池可以防止更多的内存碎片的产生
6. 更方便于管理内存

##### **数据结构**

为了能够分配大小可变的对象，显然我们需要管理空闲内存块，我们可以用一个链表把所有内存块链接起来，然后使用一个指针来记录当前空闲内存块的位置，如图所示：  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/nQzmQv.png)

从图中我们可以看到，有两个空闲内存块，空闲内存之间使用链表链接起来，每个内存块都是前一个的2倍，也就是说，当内存池中的空闲内存不足以分配时我们就向malloc申请内存，只不过其大小是前一个的2倍：  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/NRRF3i.png)

其次，我们有一个指针free_ptr，指向接下来的空闲内存块起始位置，当向内存池分配内存时找到free_ptr并判断当前内存池剩余空闲是否足够就可以了，有就分配出去并修改free_ptr，否则向malloc再次成倍申请内存。  

从这里的设计可以看出，我们的内存池其实是不会提供类似free这样的内存释放函数的，如果要释放内存，那么会一次性将整个内存池释放掉，这一点和通用的内存分配器是不一样。  

现在，我们可以分配内存了，还有一个问题是所有内存池设计不得不考虑的，那就是线程安全，这个话题你可以参考这里。  

##### **线程安全**

显然，内存池不应该局限在单线程场景，那我们的内存池要怎样实现线程安全呢？  

有的同学可能会说这还不简单，直接给内存池一把锁保护就可以了。  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/FV7J3e.png)

这种方法是不是可行呢？还是那句话，It depends，要看情况。  

如果你的程序有大量线程申请释放内存，那么这种方案下锁的竞争将会非常激烈，线程这样的场景下使用该方案不会有很好的性能。  

那么还有没有一种更好的办法吗？答案是肯定的。  

##### **线程局部存储**    

既然多线程使用线程池存在竞争问题，那么干脆我们为每个线程维护一个内存池就好了，这样多线程间就不存在竞争问题了。  

那么我们该怎样为每个线程维护一个内存池呢？  

线程局部存储，Thread Local Storage正是用于解决这一类问题的，什么是线程局部存储呢？  

简单说就是，我们可以创建一个全局变量，因此所有线程都可以使用该全局变量，但与此同时，我们将该全局变量声明为线程私有存储，那么这时虽然所有线程依然看似使用同一个全局变量，但该全局变量在每个线程中都有自己的副本，**变量指向的值是线程私有的**，相互之间不会干扰。  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/2y6bmi.png)

假设这个全局变量是一个整数，变量名字为global_value，初始值为100，那么当线程A将global_value修改为200时，线程B看到的global_value的值依然为100，只有线程A看到的global_value为200，这就是线程局部存储的作用。  

##### **线程局部存储+内存池**   

有了线程局部存储问题就简单了，我们可以将内存池声明为线程局部存储，这样每个线程都只会操作属于自己的内存池，这样就再也不会有锁竞争问题了。  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/ZBvuQr.png)

注意，虽然这里给出了线程局部存储的设计，但并不是说加锁的方案就比不上线程局部存储方案，还是那句话，一切要看使用场景，如果加锁的方案够用，那么我们就没有必要绞尽脑汁的去用其它方案，因为加锁的方案更简单，代码也更容易维护。  

还需要提醒的是，这里只是给出了内存池的一种实现方法，并不是说所有内存池都要这么设计，内存池可以简单也可复杂，一切要看实际场景，这一点也需要注意。  

##### **其它内存池形式**   

到目前为止我们给出了两种内存池的设计方法，第一种是提前创建出一堆需要的对象（数据结构），自己维护好哪些对象（数据结构）可用哪些已被分配；第二种可以申请任意大小的内存空间，使用过程中只申请不释放，最后一次性释放。这两种内存池天然适用于服务器端编程。  

最后我们再来介绍一种内存池实现技术，这种内存池会提前申请出一大段内存，然后将这一大段内存切分为大小相同的小内存块：  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/2qUbe2.png)

然后我们自己来维护这些被切分出来的小内存块哪些是空闲的哪些是已经被分配的，比如我们可以使用栈这种数据结构，最初把所有空闲内存块地址push到栈中，分配内存是就pop出来一个，用户使用完毕后再push回栈里。  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/Zru2u2.png)

从这里的设计我们可以看出，这种内存池有一个限制，这个限制就是说**程序申请的最大内存不能超过这里内存块的大小**，否则不足以装下用户数据，这需要我们对程序所涉及的业务非常了解才可以。  

用户申请到内存后根据需要将其塑造成特定对象（数据结构）。  

关于线程安全的问题，可以同样采用线程局部存储的方式来实现：  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/zUnAve.png)

**一个有趣的问题**   

除了线程安全，这里还有一个非常有趣的问题，那就是如果线程A申请的对象被线程B拿去释放，我们的内存池该怎么处理呢？  

这个问题之所以有趣是因为我们**必须知道该内存属于哪个线程的局部存储，但申请的内存本身并不能告诉你这样的信息**。  

有的同学可能会说这还不简单，不就是一个指针到另一个指针的映射吗，直接用map之类存起来就好了，但问题并没有这么简单，原因就在于如果我们切分的内存块很小，那么会存在大量内存块，这就需要存储大量的映射关系，有没有办法改进呢？  

改进方法是这样的，一般来说，我们申请到的大段内存其实是会按照特定大小进行内存对齐，我们假设总是按照4K字节对齐，那么该大段内存的起始地址后12个bit(4K = 2^12)为总是0，比如地址0x9abcd**000**，同时我们也假设申请到的大段内存大小也是4K：  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/YnYVve.png)

那么我们就能知道该大段内存中的各个小内存块起始地址除了后12个bit位外都是一样的：  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/6NjEBb.png)

这样拿到任意一个内存的地址我们就能知道对应的大段内存的起始地址，只需要简单的将后12个bit置为0即可，有了大段内存的起始地址剩下的就简单了，我们可以在大段内存中的最后保存对应的线程局部存储信息：  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/ryuqM3.png)

**这样我们对任意一个内存块地址进行简单的位运算就可以得到对应的线程局部存储信息**，大大减少了维护映射信息对内存的占用。

# Linux文件锁与记录锁

Linux文件锁用于同步多个进程对同一文件执行的IO操作，防止出现竞争状态。

文件锁分为建议性锁与强制性锁：

- 建议性锁用于协同多进程，即多个已知进程间的同步；每个进程都按照加锁，读写文件，解锁的步骤对同一文件执行IO操作；若文件已被其他进程锁定，则当前进程将等待或以失败返回；建议性锁并不能阻止其他进程在文件已加锁的情况下，不获得锁而强制执行与锁的类型相冲突的IO操作。
- 强制性锁除可用于协同多进程外，还可用于保护文件内容，以防止其他进程强制读写已被当前进程加锁的文件。

### flock

```c
#include <sys/file.h>

int flock(int fd, int operation);
```

fd指定用于引用文件的文件描述符

operation指定对该文件执行的相关锁操作

- LOCK_SH：设置共享（读）锁
- LOCK_EX：设置独占（写）锁
- LOCK_UN：解锁
- 默认情况下，若其他进程已对fd指定的文件加锁，则当前进程对该文件加锁时将被阻塞，直到对该文件加锁的进程执行解锁；若LOCK_SH或LOCK_EX与该标志进行按位或操作，则当前进程立即以失败返回，并将errno设置为EWOULDBLOCK/EAGAIN

进程对未加锁的文件执行解锁操作，或对已解锁的文件再次执行解锁操作，都不会产生错误。

对于同一文件，多个进程都可以设置共享锁，但在任一时间点，仅单一进程可以对该文件设置独占锁，且其他进程无法对该文件设置共享锁与独占锁，否则将以EWOULDBLOCK/EAGAIN错误失败，即同一文件的独占锁排斥所有其他类型的锁。

### fcntl

```c
#include <unistd.h>
#include <fcntl.h>

int fcntl(int fd, int cmd, struct flock *flockstr);
```

fd指定用于引用文件的文件描述符

flockstr指定锁的属性

```c
struct flock {
    short l_type;
    short l_whence;
    off_t l_start;
    off_t l_len;
    pid_t l_pid;
};
```

l_type指定锁的类型，可以设置为F_RDLCK/F_WRLCK/F_UNLCK，含义分别与flock(2)的LOCK_SH/LOCK_EX/LOCK_UN一致，且加锁的规则与flock(2)相同，即共享锁数量任意，独占锁单一且排他。

l_whence，l_start，l_len共同设置锁定区域：
l_whence与lseek(2)的whence参数含义相同，可以设置为SEEK_SET/SEEK_CUR/SEEK_END分别表示文件起始/文件当前偏移/文件末尾
l_start指定相对于l_whence的起始字节偏移数；l_whence为SEEK_CUR或SEEK_END时，l_start可以指定为负值
l_len指定从l_start与l_whence计算得出的偏移值开始，锁定区域的字节长度

- 值为0，表示从l_start与l_whence计算得出的偏移值开始，至文件末尾，而不论文件长度的变化
- 值为正数，表示[l_start, l_start+l_len-1]
- 值为负数，表示[l_start+l_len, l_start-1]

锁定的区域可以超过文件末尾，但l_start与l_len为负数时，与l_whence计算得出的偏移值不能超过文件起始位置，即字节0。

cmd指定对文件区域设置锁的方式

- F_SETLK：加锁(F_RDLCK/F_WRLCK)或解锁(F_UNLCK)；若该操作与其他进程对该文件区域的锁相冲突，则返回-1，并将errno设置为EACCES或EAGAIN。
- F_SETLKW：与F_SETLK相同，但与其他进程对该文件区域的锁相冲突时将阻塞，等待解锁；等待过程中若被信号中断，则返回-1，并将errno设置为EINTR。
- F_GETLK：检查是否可对文件指定区域加锁，但并不实际执行锁定操作，此时l_type值必须为F_RDLCK或F_WRLCK；若当前进程可以对文件内的指定区域加锁，则通过l_type返回F_UNLCK；若与其他进程的锁相冲突，则分别通过l_type返回锁的类型，l_whence，l_start，l_len返回锁定区域，l_pid返回锁定该文件区域的进程PID。

对文件区域解锁将立即返回，对并未加锁的区域解锁不会产生错误。

由于独占锁排斥所有其他类型的锁，因此若某进程已对某文件设置了共享锁，而其他进程请求对该文件设置独占锁时，将出现锁饥饿而可能被无限阻塞。

共享锁与独占锁之间没有优先级关系，对于多个对同一文件请求设置锁的进程，内核将按进程调度的顺序而非请求锁的顺序处理。

# 信号量与互斥量

信号量用在**多线程多任务同步**的，一个线程完成了某一个动作就通过信号量告诉别的线程，别的线程再进行某些动作。

互斥锁是用在多线程多任务互斥的，一个线程占用了某一个资源，那么别的线程就无法访问，直到这个线程unlock，其他的线程才开始可以利用这个资源。比如对全局变量的访问，有时要加锁，操作完了，在解锁。

尽管两个概念有点类似，但是他们的侧重点不一样，信号量不一定是锁定某一个资源，而是流程上的概念，比如：有A，B两个线程，B线程要等A线程完成某一任务以后再进行自己下面的步骤，这个任务并不一定是锁定某一资源，还可以是进行一些计算或者数据处理之类。而线程互斥量则是“锁住某一资源”的概念，在锁定期间内，其他线程无法对被保护的数据进行操作。不难看出，mutex是semaphore的一种特殊情况（n=1时）。也就是说，完全可以用后者替代前者。**但是，因为mutex较为简单，且效率高，所以在必须保证资源独占的情况下，还是采用这种设计**。

# 临界资源

临界资源是指每次仅允许一个进程访问的资源。属于临界资源的硬件有打印机、磁带机等，软件有消息缓冲队列、变量、数组、缓冲区等。诸进程间应采取互斥方式，实现对这种资源的共享。

每个进程中访问临界资源的那段代码称为临界区。显然，若能保证诸进程互斥地进入自己的临界区，便可实现诸进程对临界资源的互斥访问。为此，每个进程在进入临界区之前，应先对欲访问的临界资源进行检查，看它是否正被访问。如果此刻该临界资源未被访问，进程便可进入临界区对该资源进行访问，并设置它正被访问的标志；如果此刻该临界资源正被某进程访问，则本进程不能进入临界区。

为禁止两个进程同时进入临界区，同步机制应遵循以下准则：

- 空闲让进。临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区。
- 忙则等待。当已有进程进入临界区时，其他试图进入临界区的进程必须等待。
- 有限等待。对请求访问的进程，应保证能在有限时间内进入临界区。
- 让权等待。当进程不能进入临界区时，应立即释放处理器，防止进程忙等待。

# 服务器未监听任何端口

RST是复位报文，TCP连接中出现RST的情况有如下几种：

1. 端口未打开

2. 请求超时

3. 提前关闭

4. 在一个已经关闭的socket上收到数据

# 客户端向服务端发起tcp连接时，服务端没有收到请求这样子

如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发超时重传机制。

在 Linux 里，客户端的 SYN 报文最大重传次数由 `tcp_syn_retries`内核参数控制，这个参数是可以自定义的，默认值一般是 5。

通常，第一次超时重传是在 1 秒后，第二次超时重传是在 2 秒，第三次超时重传是在 4 秒后，第四次超时重传是在 8 秒后，第五次是在超时重传 16 秒后。没错，每次超时的时间是上一次的 2 倍。

# 服务器的高可用

 “高可用性”（High Availability）通常来描述一个系统经过专门的设计，从而减少停工时间，而保持其服务的高度可用性。所以当我们一说到高可用，我们满脑子都是以负载均衡为主心骨搭建的拓扑图，以他为中心，从单节点拓展为多节点，消灭单点故障。但随着我们业务架构越来越庞大复杂，那么要考虑的就不再只是服务器维度的高可用了。接下来，我来给大家介绍一下不同维度的“高可用”在架构上是如何实现的。

## 通用高可用

​    很多人在搭建业务的时候喜欢用一台高性能服务器搭建所有业务所需的应用和环境。比如服务器上搭建Nginx、会员系统、订单系统、自建数据库等等。这类搭建的初衷大概有简单省事、预算不足、初期业务量小感觉够用等因素。
这些困难业主要集中在业务上线初期，都是很现实的问题，不过随之带来的是更加现实的困难。性能瓶颈很快到来，后期调整架构会因越来越大的数据量和停服带来收益减少等等问题。
所以业务初期搭建一个基础高可用框架，日后根据需要逐渐添加功能。
![1](https://yqfile.alicdn.com/5ddb148031cee39cb3c112aa0e485d4a24c83320.png)

A、后期业务增加后我们再根据需要逐步扩容，例如数据库读写压力大了，我们用Redis、数据库读写分离等手段。这样扩容不用复杂的操作，不用长时间的停服迁移重要的数据信息。
![2](https://yqfile.alicdn.com/64d3c349e3be475e837f64463905ef47bb0a8073.png)

B、再后来业务量进一步扩大，需要短信服务、需要组网、需要安全防护等等，都可以灵活拓展。所以对于服务器层面来说，一开始就搭建一个高可用架构是至关重要的。

## 进阶高可用

容灾方面：
通常对于一个普通的APP、门户网站、内部系统等等业务，通用高可用已经足够了。但为了实现客户们日益提高的对体验感的的高要求，工程师们不知踏平了多少坑以后实践出了与之对应的高级高可用架构。这种架构不再针对某一个业务集群做高可用，而是以业务为维度。举个例子当某一个地域的业务不可用时，能有其他地域的备用集群顶上。

![3](https://yqfile.alicdn.com/30d6434a064b8fa7e9f42d53d7a0eaf2adcce67d.png)

![4](https://yqfile.alicdn.com/c69349a09f7f571d9d67a7dc9764b96d059120dd.png)

客户体验感：
当业务做大到一定程度，客户群体就不仅仅局限于一个市或者一个省，乃至一个国家。这时候，因为客户离业务集群太远，导致通讯质量不佳，延迟、丢包问题层出不穷。以前我们经常用“三秒”来定义一个网站的好坏，但现在主流网站大多均已采用“1.5秒”来打分了。传统的单业务节点越来越难满足了，那就得考虑多节点同时运行承载业务，可通过全局流量来实现。而多节点之间的数据同步可以用阿里云的云企业网来实现。

负载均衡从其应用的地理结构上分为本地负载均衡和全局负载均衡。本地负载均衡是指对同地域的服务器群做负载均衡，全局负载均衡是指对分别部署在不同地域有不同网络结构的服务器群做负载均衡。
• 多线路智能化解析服务
全局流量管理利用DNS智能解析和应用服务的运行状态健康检查，将用户访问定向到最合适的IP地址，使访问用户获得最快捷、最流畅的体验。
• 跨地域容灾
全局流量支持将不同地域的IP地址添加到不同的地址池，并配置健康检查。在访问策略配置中，设置默认地址池为地址池甲，Failover地址池为地址池乙，即可以实现应用服务主备IP容灾切换。
• 不同地域访问加速
使用全局流量管理，可以使不同地域的用户访问不同的IP地址池，实现用户分组管理，分组接入，帮助应用服务提高用户访问体验。

![5](https://yqfile.alicdn.com/4ffb23dc6664720e8d75290242135d4a3063e72b.png)

这样我们也就能搭建一个便于客户就近访问的业务集群了，而用CEN组网打通各机房VPC，数据同步方面的工作也能变得更简单。

# 从代码到机器运行

gcc -o HelloWorld.c，就可以编译这段代码。根据编译流程分别调用预处理程序、编译程序、汇编程序、链接程序来完成具体工作。

![img](https://pic3.zhimg.com/80/v2-f2b10135ed52436888a793327e4d5a4a_720w.jpg)

![img](https://pic3.zhimg.com/80/v2-bde34df011c397ad42dc00fe6bd35226_720w.jpg)

是不是非常简单？这次我们发现读头不再来回移动了，而是靠地址总线寻找对应的“纸带格子”。读取写入数据由数据总线完成，而动作的控制就是控制总线的职责了。

## 例子

我们可以通过gcc -c -S HelloWorld得到（只能得到其汇编代码，而不能得到二进制数据）。我们用objdump -d HelloWorld程序，得到/lesson01/HelloWorld.dump，其中有很多库代码（只需关注main函数相关的代码），如下图：

![img](https://pic1.zhimg.com/80/v2-3991a042107b90612122b14596c65614_720w.jpg)

以上图中，分成四列：第一列为地址；第二列为十六进制，表示真正装入机器中的代码数据；第三列是对应的汇编代码；第四列是相关代码的注释。这是x86_64体系的代码，由此可以看出x86 CPU是变长指令集。

接下来，我们把这段代码数据装入最小电子计算机，状态如下图：

![img](https://pic3.zhimg.com/80/v2-5d4889e7bf20e670ee71cc9b6285c96e_720w.jpg)

以上，对应图中的伪代码你应该明白了：现代电子计算机正是通过内存中的信息（指令和数据）做出相应的操作，并通过内存地址的变化，达到程序读取数据，控制程序流程（顺序、跳转对应该图灵机的读头来回移动）的功能。

