[TOC]

# 从内存中访问数据的过程

总体流程：1.获得数据在内存的物理地址；2.从内存中取数据

**获取物理地址**

需要使用虚拟地址（逻辑地址）进行转化：

先查找TLB（快表：为硬件结构，保存有部分内存中页表的内容，目的是提高效率），把虚拟地址写为二进制的形式，由页面大小得到页内偏移位数，剩下的是虚拟页号，在这里虚拟页号进一步分为TLB标记和TLB组索引。由组索引和TLB标记查看有无对应的物理页号及标记位是否为”1”，若存在，把物理页号拼接页内地址得到实地址

若不存在，说明TLB不命中，查找内存中的页表。这里就相对比较单纯了，通过页号及页表寄存器找到相应的页表项，看一下有没有物理页号及有效位是否为“1”，若有，则命中，把物理页号拼接到页内地址即得到实地址；若无，则比较麻烦了，说明内存中没有要找的这个页面，产生缺页中断，需从外存调入。

**根据地址来访问数据**

先查找高速缓存Cache（内存的部分副本），在根据第一步得到的物理地址进行查找时，要了解Cache的几种映射方式，主要是直接映射方式和组相连映射方式，根据 不同的映射方式来分析上一步得到的物理地址。

一般说来，我们由Cache索引和标志位找到Cache中位置，再查看有效位是否为“1”，即Cache中是否存在要查找的内存地址中内容的副本；若为“1”，即有效，则根据偏移量（字块内地址）取出Cache单元的内容即可。如不在，则要去主存中查找对应的物理地址的内容。

# 如何减少频繁分配内存（malloc或者new）造成的内存碎片

内存池（Memory Pool）是一种内存分配方式。通常我们习惯直接使用new、malloc等API申请分配内存，这样做的缺点在于：由于所申请内存块的大小不定，当频繁使用时会造成大量的内存碎片并进而降低性能。内存池则是在真正使用内存之前，先申请分配一定数量的、大小相等（一般情况下）的内存块留作备用。当有新的内存需求时，就从内存池中分出一部分内存块，若内存块不够再继续申请新的内存。这样做的一个显著优点是尽量避免了内存碎片，使得内存分配效率得到提升。

1. 针对特殊情况，例如需要频繁分配释放固定大小的内存对象时，不需要复杂的分配算法和多线程保护。也不需要维护内存空闲表的额外开销，从而获得较高的性能。
2. 由于开辟一定数量的连续内存空间作为内存池块，因而一定程度上提高了程序局部性，提升了程序性能。
3. 比较容易控制页边界对齐和内存字节对齐，没有内存碎片的问题。
4. 当需要分配管理的内存在100M一下的时候，采用内存池会节省大量的时间，否则会耗费更多的时间。
5. 内存池可以防止更多的内存碎片的产生
6. 更方便于管理内存

##### **数据结构**

为了能够分配大小可变的对象，显然我们需要管理空闲内存块，我们可以用一个链表把所有内存块链接起来，然后使用一个指针来记录当前空闲内存块的位置，如图所示：  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/nQzmQv.png)

从图中我们可以看到，有两个空闲内存块，空闲内存之间使用链表链接起来，每个内存块都是前一个的2倍，也就是说，当内存池中的空闲内存不足以分配时我们就向malloc申请内存，只不过其大小是前一个的2倍：  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/NRRF3i.png)

其次，我们有一个指针free_ptr，指向接下来的空闲内存块起始位置，当向内存池分配内存时找到free_ptr并判断当前内存池剩余空闲是否足够就可以了，有就分配出去并修改free_ptr，否则向malloc再次成倍申请内存。  

从这里的设计可以看出，我们的内存池其实是不会提供类似free这样的内存释放函数的，如果要释放内存，那么会一次性将整个内存池释放掉，这一点和通用的内存分配器是不一样。  

现在，我们可以分配内存了，还有一个问题是所有内存池设计不得不考虑的，那就是线程安全，这个话题你可以参考这里。  

##### **线程安全**

显然，内存池不应该局限在单线程场景，那我们的内存池要怎样实现线程安全呢？  

有的同学可能会说这还不简单，直接给内存池一把锁保护就可以了。  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/FV7J3e.png)

这种方法是不是可行呢？还是那句话，It depends，要看情况。  

如果你的程序有大量线程申请释放内存，那么这种方案下锁的竞争将会非常激烈，线程这样的场景下使用该方案不会有很好的性能。  

那么还有没有一种更好的办法吗？答案是肯定的。  

##### **线程局部存储**    

既然多线程使用线程池存在竞争问题，那么干脆我们为每个线程维护一个内存池就好了，这样多线程间就不存在竞争问题了。  

那么我们该怎样为每个线程维护一个内存池呢？  

线程局部存储，Thread Local Storage正是用于解决这一类问题的，什么是线程局部存储呢？  

简单说就是，我们可以创建一个全局变量，因此所有线程都可以使用该全局变量，但与此同时，我们将该全局变量声明为线程私有存储，那么这时虽然所有线程依然看似使用同一个全局变量，但该全局变量在每个线程中都有自己的副本，**变量指向的值是线程私有的**，相互之间不会干扰。  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/2y6bmi.png)

假设这个全局变量是一个整数，变量名字为global_value，初始值为100，那么当线程A将global_value修改为200时，线程B看到的global_value的值依然为100，只有线程A看到的global_value为200，这就是线程局部存储的作用。  

##### **线程局部存储+内存池**   

有了线程局部存储问题就简单了，我们可以将内存池声明为线程局部存储，这样每个线程都只会操作属于自己的内存池，这样就再也不会有锁竞争问题了。  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/ZBvuQr.png)

注意，虽然这里给出了线程局部存储的设计，但并不是说加锁的方案就比不上线程局部存储方案，还是那句话，一切要看使用场景，如果加锁的方案够用，那么我们就没有必要绞尽脑汁的去用其它方案，因为加锁的方案更简单，代码也更容易维护。  

还需要提醒的是，这里只是给出了内存池的一种实现方法，并不是说所有内存池都要这么设计，内存池可以简单也可复杂，一切要看实际场景，这一点也需要注意。  

##### **其它内存池形式**   

到目前为止我们给出了两种内存池的设计方法，第一种是提前创建出一堆需要的对象（数据结构），自己维护好哪些对象（数据结构）可用哪些已被分配；第二种可以申请任意大小的内存空间，使用过程中只申请不释放，最后一次性释放。这两种内存池天然适用于服务器端编程。  

最后我们再来介绍一种内存池实现技术，这种内存池会提前申请出一大段内存，然后将这一大段内存切分为大小相同的小内存块：  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/2qUbe2.png)

然后我们自己来维护这些被切分出来的小内存块哪些是空闲的哪些是已经被分配的，比如我们可以使用栈这种数据结构，最初把所有空闲内存块地址push到栈中，分配内存是就pop出来一个，用户使用完毕后再push回栈里。  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/Zru2u2.png)

从这里的设计我们可以看出，这种内存池有一个限制，这个限制就是说**程序申请的最大内存不能超过这里内存块的大小**，否则不足以装下用户数据，这需要我们对程序所涉及的业务非常了解才可以。  

用户申请到内存后根据需要将其塑造成特定对象（数据结构）。  

关于线程安全的问题，可以同样采用线程局部存储的方式来实现：  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/zUnAve.png)

**一个有趣的问题**   

除了线程安全，这里还有一个非常有趣的问题，那就是如果线程A申请的对象被线程B拿去释放，我们的内存池该怎么处理呢？  

这个问题之所以有趣是因为我们**必须知道该内存属于哪个线程的局部存储，但申请的内存本身并不能告诉你这样的信息**。  

有的同学可能会说这还不简单，不就是一个指针到另一个指针的映射吗，直接用map之类存起来就好了，但问题并没有这么简单，原因就在于如果我们切分的内存块很小，那么会存在大量内存块，这就需要存储大量的映射关系，有没有办法改进呢？  

改进方法是这样的，一般来说，我们申请到的大段内存其实是会按照特定大小进行内存对齐，我们假设总是按照4K字节对齐，那么该大段内存的起始地址后12个bit(4K = 2^12)为总是0，比如地址0x9abcd**000**，同时我们也假设申请到的大段内存大小也是4K：  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/YnYVve.png)

那么我们就能知道该大段内存中的各个小内存块起始地址除了后12个bit位外都是一样的：  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/6NjEBb.png)

这样拿到任意一个内存的地址我们就能知道对应的大段内存的起始地址，只需要简单的将后12个bit置为0即可，有了大段内存的起始地址剩下的就简单了，我们可以在大段内存中的最后保存对应的线程局部存储信息：  

![img](https://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2021/3/ryuqM3.png)

**这样我们对任意一个内存块地址进行简单的位运算就可以得到对应的线程局部存储信息**，大大减少了维护映射信息对内存的占用。

# Linux文件锁与记录锁

Linux文件锁用于同步多个进程对同一文件执行的IO操作，防止出现竞争状态。

文件锁分为建议性锁与强制性锁：

- 建议性锁用于协同多进程，即多个已知进程间的同步；每个进程都按照加锁，读写文件，解锁的步骤对同一文件执行IO操作；若文件已被其他进程锁定，则当前进程将等待或以失败返回；建议性锁并不能阻止其他进程在文件已加锁的情况下，不获得锁而强制执行与锁的类型相冲突的IO操作。
- 强制性锁除可用于协同多进程外，还可用于保护文件内容，以防止其他进程强制读写已被当前进程加锁的文件。

### flock

```c
#include <sys/file.h>

int flock(int fd, int operation);
```

fd指定用于引用文件的文件描述符

operation指定对该文件执行的相关锁操作

- LOCK_SH：设置共享（读）锁
- LOCK_EX：设置独占（写）锁
- LOCK_UN：解锁
- 默认情况下，若其他进程已对fd指定的文件加锁，则当前进程对该文件加锁时将被阻塞，直到对该文件加锁的进程执行解锁；若LOCK_SH或LOCK_EX与该标志进行按位或操作，则当前进程立即以失败返回，并将errno设置为EWOULDBLOCK/EAGAIN

进程对未加锁的文件执行解锁操作，或对已解锁的文件再次执行解锁操作，都不会产生错误。

对于同一文件，多个进程都可以设置共享锁，但在任一时间点，仅单一进程可以对该文件设置独占锁，且其他进程无法对该文件设置共享锁与独占锁，否则将以EWOULDBLOCK/EAGAIN错误失败，即同一文件的独占锁排斥所有其他类型的锁。

### fcntl

```c
#include <unistd.h>
#include <fcntl.h>

int fcntl(int fd, int cmd, struct flock *flockstr);
```

fd指定用于引用文件的文件描述符

flockstr指定锁的属性

```c
struct flock {
    short l_type;
    short l_whence;
    off_t l_start;
    off_t l_len;
    pid_t l_pid;
};
```

l_type指定锁的类型，可以设置为F_RDLCK/F_WRLCK/F_UNLCK，含义分别与flock(2)的LOCK_SH/LOCK_EX/LOCK_UN一致，且加锁的规则与flock(2)相同，即共享锁数量任意，独占锁单一且排他。

l_whence，l_start，l_len共同设置锁定区域：
l_whence与lseek(2)的whence参数含义相同，可以设置为SEEK_SET/SEEK_CUR/SEEK_END分别表示文件起始/文件当前偏移/文件末尾
l_start指定相对于l_whence的起始字节偏移数；l_whence为SEEK_CUR或SEEK_END时，l_start可以指定为负值
l_len指定从l_start与l_whence计算得出的偏移值开始，锁定区域的字节长度

- 值为0，表示从l_start与l_whence计算得出的偏移值开始，至文件末尾，而不论文件长度的变化
- 值为正数，表示[l_start, l_start+l_len-1]
- 值为负数，表示[l_start+l_len, l_start-1]

锁定的区域可以超过文件末尾，但l_start与l_len为负数时，与l_whence计算得出的偏移值不能超过文件起始位置，即字节0。

cmd指定对文件区域设置锁的方式

- F_SETLK：加锁(F_RDLCK/F_WRLCK)或解锁(F_UNLCK)；若该操作与其他进程对该文件区域的锁相冲突，则返回-1，并将errno设置为EACCES或EAGAIN。
- F_SETLKW：与F_SETLK相同，但与其他进程对该文件区域的锁相冲突时将阻塞，等待解锁；等待过程中若被信号中断，则返回-1，并将errno设置为EINTR。
- F_GETLK：检查是否可对文件指定区域加锁，但并不实际执行锁定操作，此时l_type值必须为F_RDLCK或F_WRLCK；若当前进程可以对文件内的指定区域加锁，则通过l_type返回F_UNLCK；若与其他进程的锁相冲突，则分别通过l_type返回锁的类型，l_whence，l_start，l_len返回锁定区域，l_pid返回锁定该文件区域的进程PID。

对文件区域解锁将立即返回，对并未加锁的区域解锁不会产生错误。

由于独占锁排斥所有其他类型的锁，因此若某进程已对某文件设置了共享锁，而其他进程请求对该文件设置独占锁时，将出现锁饥饿而可能被无限阻塞。

共享锁与独占锁之间没有优先级关系，对于多个对同一文件请求设置锁的进程，内核将按进程调度的顺序而非请求锁的顺序处理。

# 信号量与互斥量

信号量用在**多线程多任务同步**的，一个线程完成了某一个动作就通过信号量告诉别的线程，别的线程再进行某些动作。

互斥锁是用在多线程多任务互斥的，一个线程占用了某一个资源，那么别的线程就无法访问，直到这个线程unlock，其他的线程才开始可以利用这个资源。比如对全局变量的访问，有时要加锁，操作完了，在解锁。

尽管两个概念有点类似，但是他们的侧重点不一样，信号量不一定是锁定某一个资源，而是流程上的概念，比如：有A，B两个线程，B线程要等A线程完成某一任务以后再进行自己下面的步骤，这个任务并不一定是锁定某一资源，还可以是进行一些计算或者数据处理之类。而线程互斥量则是“锁住某一资源”的概念，在锁定期间内，其他线程无法对被保护的数据进行操作。不难看出，mutex是semaphore的一种特殊情况（n=1时）。也就是说，完全可以用后者替代前者。**但是，因为mutex较为简单，且效率高，所以在必须保证资源独占的情况下，还是采用这种设计**。

# 临界资源

临界资源是指每次仅允许一个进程访问的资源。属于临界资源的硬件有打印机、磁带机等，软件有消息缓冲队列、变量、数组、缓冲区等。诸进程间应采取互斥方式，实现对这种资源的共享。

每个进程中访问临界资源的那段代码称为临界区。显然，若能保证诸进程互斥地进入自己的临界区，便可实现诸进程对临界资源的互斥访问。为此，每个进程在进入临界区之前，应先对欲访问的临界资源进行检查，看它是否正被访问。如果此刻该临界资源未被访问，进程便可进入临界区对该资源进行访问，并设置它正被访问的标志；如果此刻该临界资源正被某进程访问，则本进程不能进入临界区。

为禁止两个进程同时进入临界区，同步机制应遵循以下准则：

- 空闲让进。临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区。
- 忙则等待。当已有进程进入临界区时，其他试图进入临界区的进程必须等待。
- 有限等待。对请求访问的进程，应保证能在有限时间内进入临界区。
- 让权等待。当进程不能进入临界区时，应立即释放处理器，防止进程忙等待。

# 服务器未监听任何端口

RST是复位报文，TCP连接中出现RST的情况有如下几种：

1. 端口未打开

2. 请求超时

3. 提前关闭

4. 在一个已经关闭的socket上收到数据

# 客户端向服务端发起tcp连接时，服务端没有收到请求

如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发超时重传机制。

在 Linux 里，客户端的 SYN 报文最大重传次数由 `tcp_syn_retries`内核参数控制，这个参数是可以自定义的，默认值一般是 5。

通常，第一次超时重传是在 1 秒后，第二次超时重传是在 2 秒，第三次超时重传是在 4 秒后，第四次超时重传是在 8 秒后，第五次是在超时重传 16 秒后。没错，每次超时的时间是上一次的 2 倍。

# 服务器的高可用

 “高可用性”（High Availability）通常来描述一个系统经过专门的设计，从而减少停工时间，而保持其服务的高度可用性。所以当我们一说到高可用，我们满脑子都是以负载均衡为主心骨搭建的拓扑图，以他为中心，从单节点拓展为多节点，消灭单点故障。但随着我们业务架构越来越庞大复杂，那么要考虑的就不再只是服务器维度的高可用了。接下来，我来给大家介绍一下不同维度的“高可用”在架构上是如何实现的。

## 通用高可用

​    很多人在搭建业务的时候喜欢用一台高性能服务器搭建所有业务所需的应用和环境。比如服务器上搭建Nginx、会员系统、订单系统、自建数据库等等。这类搭建的初衷大概有简单省事、预算不足、初期业务量小感觉够用等因素。
这些困难业主要集中在业务上线初期，都是很现实的问题，不过随之带来的是更加现实的困难。性能瓶颈很快到来，后期调整架构会因越来越大的数据量和停服带来收益减少等等问题。
所以业务初期搭建一个基础高可用框架，日后根据需要逐渐添加功能。
![1](https://yqfile.alicdn.com/5ddb148031cee39cb3c112aa0e485d4a24c83320.png)

A、后期业务增加后我们再根据需要逐步扩容，例如数据库读写压力大了，我们用Redis、数据库读写分离等手段。这样扩容不用复杂的操作，不用长时间的停服迁移重要的数据信息。
![2](https://yqfile.alicdn.com/64d3c349e3be475e837f64463905ef47bb0a8073.png)

B、再后来业务量进一步扩大，需要短信服务、需要组网、需要安全防护等等，都可以灵活拓展。所以对于服务器层面来说，一开始就搭建一个高可用架构是至关重要的。

## 进阶高可用

容灾方面：
通常对于一个普通的APP、门户网站、内部系统等等业务，通用高可用已经足够了。但为了实现客户们日益提高的对体验感的的高要求，工程师们不知踏平了多少坑以后实践出了与之对应的高级高可用架构。这种架构不再针对某一个业务集群做高可用，而是以业务为维度。举个例子当某一个地域的业务不可用时，能有其他地域的备用集群顶上。

![3](https://yqfile.alicdn.com/30d6434a064b8fa7e9f42d53d7a0eaf2adcce67d.png)

![4](https://yqfile.alicdn.com/c69349a09f7f571d9d67a7dc9764b96d059120dd.png)

客户体验感：
当业务做大到一定程度，客户群体就不仅仅局限于一个市或者一个省，乃至一个国家。这时候，因为客户离业务集群太远，导致通讯质量不佳，延迟、丢包问题层出不穷。以前我们经常用“三秒”来定义一个网站的好坏，但现在主流网站大多均已采用“1.5秒”来打分了。传统的单业务节点越来越难满足了，那就得考虑多节点同时运行承载业务，可通过全局流量来实现。而多节点之间的数据同步可以用阿里云的云企业网来实现。

负载均衡从其应用的地理结构上分为本地负载均衡和全局负载均衡。本地负载均衡是指对同地域的服务器群做负载均衡，全局负载均衡是指对分别部署在不同地域有不同网络结构的服务器群做负载均衡。
• 多线路智能化解析服务
全局流量管理利用DNS智能解析和应用服务的运行状态健康检查，将用户访问定向到最合适的IP地址，使访问用户获得最快捷、最流畅的体验。
• 跨地域容灾
全局流量支持将不同地域的IP地址添加到不同的地址池，并配置健康检查。在访问策略配置中，设置默认地址池为地址池甲，Failover地址池为地址池乙，即可以实现应用服务主备IP容灾切换。
• 不同地域访问加速
使用全局流量管理，可以使不同地域的用户访问不同的IP地址池，实现用户分组管理，分组接入，帮助应用服务提高用户访问体验。

![5](https://yqfile.alicdn.com/4ffb23dc6664720e8d75290242135d4a3063e72b.png)

这样我们也就能搭建一个便于客户就近访问的业务集群了，而用CEN组网打通各机房VPC，数据同步方面的工作也能变得更简单。

# 从代码到机器运行

gcc -o HelloWorld.c，就可以编译这段代码。根据编译流程分别调用预处理程序、编译程序、汇编程序、链接程序来完成具体工作。

![img](https://pic3.zhimg.com/80/v2-f2b10135ed52436888a793327e4d5a4a_720w.jpg)

![img](https://pic3.zhimg.com/80/v2-bde34df011c397ad42dc00fe6bd35226_720w.jpg)

是不是非常简单？这次我们发现读头不再来回移动了，而是靠地址总线寻找对应的“纸带格子”。读取写入数据由数据总线完成，而动作的控制就是控制总线的职责了。

## 例子

我们可以通过gcc -c -S HelloWorld得到（只能得到其汇编代码，而不能得到二进制数据）。我们用objdump -d HelloWorld程序，得到/lesson01/HelloWorld.dump，其中有很多库代码（只需关注main函数相关的代码），如下图：

![img](https://pic1.zhimg.com/80/v2-3991a042107b90612122b14596c65614_720w.jpg)

以上图中，分成四列：第一列为地址；第二列为十六进制，表示真正装入机器中的代码数据；第三列是对应的汇编代码；第四列是相关代码的注释。这是x86_64体系的代码，由此可以看出x86 CPU是变长指令集。

接下来，我们把这段代码数据装入最小电子计算机，状态如下图：

![img](https://pic3.zhimg.com/80/v2-5d4889e7bf20e670ee71cc9b6285c96e_720w.jpg)

以上，对应图中的伪代码你应该明白了：现代电子计算机正是通过内存中的信息（指令和数据）做出相应的操作，并通过内存地址的变化，达到程序读取数据，控制程序流程（顺序、跳转对应该图灵机的读头来回移动）的功能。

# Linux TCP参数设置

| **参数**                      | **描述**                                                     | **默认值**          | **优化值**           |
| ----------------------------- | ------------------------------------------------------------ | ------------------- | -------------------- |
| net.core.rmem_default         | 默认的TCP数据接收窗口大小（字节）。                          | 229376              | 256960               |
| net.core.rmem_max             | 最大的TCP数据接收窗口（字节）。                              | 131071              | 513920               |
| net.core.wmem_default         | 默认的TCP数据发送窗口大小（字节）。                          | 229376              | 256960               |
| net.core.wmem_max             | 最大的TCP数据发送窗口（字节）。                              | 131071              | 513920               |
| net.core.netdev_max_backlog   | 在每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。 | 1000                | 2000                 |
| net.core.somaxconn            | 定义了系统中每一个端口最大的监听队列的长度，这是个全局的参数。 | 128                 | 2048                 |
| net.core.optmem_max           | 表示每个套接字所允许的最大缓冲区的大小。                     | 20480               | 81920                |
| net.ipv4.tcp_mem              | 确定TCP栈应该如何反映内存使用，每个值的单位都是内存页（通常是4KB）。第一个值是内存使用的下限；第二个值是内存压力模式开始对缓冲区使用应用压力的上限；第三个值是内存使用的上限。在这个层次上可以将报文丢弃，从而减少对内存的使用。对于较大的BDP可以增大这些值（注意，其单位是内存页而不是字节）。 | 94011 125351 188022 | 131072 262144 524288 |
| net.ipv4.tcp_rmem             | 为自动调优定义socket使用的内存。第一个值是为socket接收缓冲区分配的最少字节数；第二个值是默认值（该值会被rmem_default覆盖），缓冲区在系统负载不重的情况下可以增长到这个值；第三个值是接收缓冲区空间的最大字节数（该值会被rmem_max覆盖）。 | 4096 87380 4011232  | 8760 256960 4088000  |
| net.ipv4.tcp_wmem             | 为自动调优定义socket使用的内存。第一个值是为socket发送缓冲区分配的最少字节数；第二个值是默认值（该值会被wmem_default覆盖），缓冲区在系统负载不重的情况下可以增长到这个值；第三个值是发送缓冲区空间的最大字节数（该值会被wmem_max覆盖）。 | 4096 16384 4011232  | 8760 256960 4088000  |
| net.ipv4.tcp_keepalive_time   | TCP发送keepalive探测消息的间隔时间（秒），用于确认TCP连接是否有效。 | 7200                | 1800                 |
| net.ipv4.tcp_keepalive_intvl  | 探测消息未获得响应时，重发该消息的间隔时间（秒）。           | 75                  | 30                   |
| net.ipv4.tcp_keepalive_probes | 在认定TCP连接失效之前，最多发送多少个keepalive探测消息。     | 9                   | 3                    |
| net.ipv4.tcp_sack             | 启用有选择的应答（1表示启用），通过有选择地应答乱序接收到的报文来提高性能，让发送者只发送丢失的报文段，（对于广域网通信来说）这个选项应该启用，但是会增加对CPU的占用。 | 1                   | 1                    |
| net.ipv4.tcp_fack             | 启用转发应答，可以进行有选择应答（SACK）从而减少拥塞情况的发生，这个选项也应该启用。 | 1                   | 1                    |
| net.ipv4.tcp_timestamps       | TCP时间戳（会在TCP包头增加12个字节），以一种比重发超时更精确的方法（参考RFC 1323）来启用对RTT 的计算，为实现更好的性能应该启用这个选项。 | 1                   | 1                    |
| net.ipv4.tcp_window_scaling   | 启用RFC 1323定义的window scaling，要支持超过64KB的TCP窗口，必须启用该值（1表示启用），TCP窗口最大至1GB，TCP连接双方都启用时才生效。 | 1                   | 1                    |
| net.ipv4.tcp_syncookies       | 表示是否打开TCP同步标签（syncookie），内核必须打开了CONFIG_SYN_COOKIES项进行编译，同步标签可以防止一个套接字在有过多试图连接到达时引起过载。 | 1                   | 1                    |
| net.ipv4.tcp_tw_reuse         | 表示是否允许将处于TIME-WAIT状态的socket（TIME-WAIT的端口）用于新的TCP连接 。 | 0                   | 1                    |
| net.ipv4.tcp_tw_recycle       | 能够更快地回收TIME-WAIT套接字。                              | 0                   | 1                    |
| net.ipv4.tcp_fin_timeout      | 对于本端断开的socket连接，TCP保持在FIN-WAIT-2状态的时间（秒）。对方可能会断开连接或一直不结束连接或不可预料的进程死亡。 | 60                  | 30                   |
| net.ipv4.ip_local_port_range  | 表示TCP/UDP协议允许使用的本地端口号                          | 32768 61000         | 1024 65000           |
| net.ipv4.tcp_max_syn_backlog  | 对于还未获得对方确认的连接请求，可保存在队列中的最大数目。如果服务器经常出现过载，可以尝试增加这个数字。 | 2048                | 2048                 |

# 实现TCP

```
int socket( int af, int type, int protocol);
```

**af**：指定一个协议簇（协议域），常见有AF_INET──指定为IPv4协议，AF_INET6──指定为IPv6，AF_LOCAL──指定为UNIX 协议域等。它值都是系统预先定义的宏，系统支持哪些协议我们才可以使用，否则会调用失败。协议簇是网络层的协议。
**type**：指定socket类型，常用的socket类型有：TCP（SOCK_STREAM）、UDP（SOCK_DGRAM）、SOCK_SEQPACKET、SOCK_RAW等，分别表明字节流、数据报、有序分组、原始套接口。
这实际上是指定内核为我们提供的服务抽象（需要注意的，并不是每一种协议簇都支持这里的所有的类型，所以类型与协议簇要匹配）。
**protocol**：指定相应的传输协议，也就是诸如TCP或UDP协议等等，系统针对每一个协议簇与类型提供了一个默认的协议（protocol设置为0使用默认协议）。常用的协议有：IPPROTO_TCP、IPPROTO_UDP、IPPROTO_STCP、IPPROTO_TIPC等，它们分别对应TCP传输协议、UDP传输协议、STCP传输协议、TIPC传输协议。

SOCK_STREAM 类型：提供有序的、可靠的、双向的和基于连接的字节流，使用带外数据传送机制，为Internet地址族使用TCP。SOCK_STREAM类型的套接口为全双向的字节流。对于流类套接口，在接收或发送数据前必需处于已连接状态。用connect()调用建立与另一套接口的连接，连接成功后，即可用send()和recv()传送数据。当会话结束后，调用closesocket()。带外数据根据规定用send()和recv()来接收。实现SOCK_STREAM类型套接口的通讯协议保证数据不会丢失也不会重复。如果终端协议有缓冲区空间，且数据不能在一定时间成功发送，则认为连接中断，其后续的调用也将以WSAETIMEOUT错误返回。
SOCK_DGRAM 类型：支持无连接的、不可靠的和使用固定大小（通常很小）缓冲区的数据报服务，为Internet地址族使用UDP。SOCK_DGRAM类型套接口允许使用sendto()和recvfrom()从任意端口发送或接收数据报。如果这样一个套接口用connect()与一个指定端口连接，则可用send()和recv()与该端口进行数据报的发送与接收

一般情况：

-  send(),recv()用于TCP，
- sendto()及recvfrom()用于UDP
- 但是send(),recv()也可以用于UDP，sendto()及recvfrom()也可以用于TCP

# 系统资源无法满足TCP

socket返回错误码

| errnos        | AIX® 错误号 | HP-UX 错误号 | Solaris 错误号 | Linux 错误号 | 描述                                                         |
| :------------ | :---------- | :----------- | :------------- | :----------- | :----------------------------------------------------------- |
| EINTR         | 4           | 4            | 4              | 4            | 指定的函数被信号中断。                                       |
| EBADF         | 9           | 9            | 9              | 9            | 套接字错误。套接字可能已损坏。                               |
| EAGAIN        | 11          | 11           | 11             | 11           | 资源暂时不可用。                                             |
| EFAULT        | 14          | 14           | 14             | 14           | 地址错误。在连接时，使用了错误地址。在接收时，数据被定向到不存在的或受保护的进程地址空间部分。缓冲区无效。 |
| EBUSY         | 16          | 16           | 16             | 16           | 资源正忙。                                                   |
| EINVAL        | 22          | 22           | 22             | 22           | 传递至指定函数或套接字的无效自变量已关闭。如果存在内存覆盖或缓存溢出问题，那么可能返回 EINVAL 错误。 |
| ENFILE        | 23          | 23           | 23             | 23           | 系统中打开的文件太多。                                       |
| EMFILE        | 24          | 24           | 24             | 24           | 每进程文件描述符表已满。已超出进程的文件描述符/套接字数。    |
| ENOSPC        | 28          | 28           | 28             | 28           | 设备或系统表上未余下任何空间。                               |
| EPIPE         | 32          | 32           | 32             | 32           | 管道中断。                                                   |
| EWOULDBLOCK   | 54          | 246          | 11             | 11           | 在连接函数上，分配给 TCP/UDP 临时端口的范围已用完。（某些操作系统将同一错误返回为 EAGAIN。） |
| ENOTSOCK      | 57          | 216          | 95             | 88           | 对非套接字执行了套接字操作。                                 |
| ENOPROTOOPT   | 61          | 220          | 99             | 92           | 选项未知。                                                   |
| EADDRINUSE    | 67          | 226          | 125            | 98           | 已经在使用指定的地址。建立该连接的先前进程可能异常终止或未正确清除。 |
| EADDRNOTAVAIL | 68          | 227          | 126            | 99           | 不能从本地系统获取指定的主机名或 IP 地址。                   |
| ENETDOWN      | 69          | 228          | 127            | 100          | 网络已停止。                                                 |
| ENETUNREACH   | 70          | 229          | 128            | 101          | 没有任何至网络或主机的路由可用。                             |
| ENETRESET     | 71          | 230          | 129            | 102          | 网络在重置时删除了该连接。                                   |
| ECONNRESET    | 73          | 232          | 131            | 104          | 合作伙伴已重置连接。                                         |
| ENOBUFS       | 74          | 233          | 132            | 105          | 系统中没有足够的内存或资源可用来完成调用。                   |
| EISCONN       | 75          | 234          | 133            | 106          | 已连接该套接字。                                             |
| ENOTCONN      | 76          | 235          | 134            | 107          | 未连接套接字。                                               |
| ETIMEDOUT     | 78          | 238          | 145            | 110          | 连接已超时。                                                 |
| ECONNREFUSED  | 79          | 239          | 146            | 111          | 连接被拒绝。如果您尝试连接至数据库，请检查服务器上的数据库管理器和 TCP/IP 协议支持是否已成功启动。如果指定了 SOCKS 协议支持，那么还必须确保 SOCKS 服务器上的 TCP/IP 协议支持已成功启动。 |
| EHOSTDOWN     | 80          | 241          | 147            | 112          | 主机已当机。                                                 |
| EHOSTUNREACH  | 81          | 242          | 148            | 113          | 没有任何至主机的可用路由。                                   |

# 发送一个包，一直都没有响应，一个线程就会卡死在这里吗

当使用 read()/recv() 读取数据时：

1) 首先会检查缓冲区，如果缓冲区中有数据，那么就读取，否则函数会被阻塞，直到网络上有数据到来。

2) 如果要读取的数据长度小于缓冲区中的数据长度，那么就不能一次性将缓冲区中的所有数据读出，剩余数据将不断积压，直到有 read()/recv() 函数再次读取。

3) 直到读取到数据后 read()/recv() 函数才会返回，否则就一直被阻塞。

解决

1. 套接字选项: SO_SNDTIMEO, SO_RCVTIMEO，调用setsockopt设置读/写超时时间。SO_RCVTIMEO是接收超时,SO_SNDTIMEO是发送超时。这种方式也不经常使用，因为这种方案不可移植，并且有些套接字的实现不支持这种方式。
2. select函数是在linux编程中很重要的一个函数，他有很多的功能，控制读、写、异常的集合，当然还有设置超时。

# 服务器响应慢了

## 排除本机自身原因

　　可以使用站长工具测试网站速度。[
](http://tool.chinaz.com/speedtest.aspx)

![img](https://images2015.cnblogs.com/blog/1044869/201705/1044869-20170516091031088-952607803.png)

## 服务器性能分析

使用top命令查看服务器的资源使用情况，主要分析CPU和内存的使用情况（top 命令是 Linux 下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，默认5秒刷新一下进程列表，所以类似于 Windows 的任务管理器。）：

　　　　![img](https://images2015.cnblogs.com/blog/1044869/201705/1044869-20170516092238463-1115064607.png)

第三行显示的是Cpu的使用情况，详细含义如下：

us---用户空间占用CPU的百分比、sy---内核空间占用CPU的百分比、ni---改变过优先级的进程占用CPU的百分比、id---空闲CPU百分比、wa---IO等待占用CPU的百分比、hi---硬中断（Hardware IRQ）占用CPU的百分比、si---软中断（Software Interrupts）占用CPU的百分比、st---Steal Time，分配给运行在主机上其它虚拟机的任务的实际CPU时间，一般只有在虚拟机OS。

第4行是当前的内存情况，服务器总内存8054352k，已使用2879468k，剩余5174884k，缓冲265728k。

我个人的理解是：当us的百分比小于50%时，是不需要去考虑服务器的配置问题的，如果服务器的us百分比长时间在70%以上时，可以考虑加强服务器的硬件配置。此外，还需要查看服务器的网络情况，下载一个大型文件基本就可以确定网络情况了。

## 项目本身分析

连接池，需要对连接池的配置进行分析（分析线程池的最大数量和释放时间等等）。

还有可能项目的设计方面不合理导致响应缓慢，这里就不详细说明了。

### 虚拟机分析

使用top指令查看虚拟机的内存占用情况，有时候可以发现虽然虚拟机占用内存的百分比不大却有明显的上限值，我们就需要去查看虚拟机的配置情况。

解决方法（以tomcat为例）：　

![img](https://images2015.cnblogs.com/blog/1044869/201705/1044869-20170516105724760-1312175352.png)

具体的数值根据实际情况而定。

## 数据库分析（MySql）

数据库的分析内容和需要考虑的方面有很多，这里只说本人遇到过的几种情况：

### 最大连接数　　　　

show variables like '%max_connections%'; 查看最大连接数
show status like 'Threads%';当前连接的使用情况

　　![img](https://images2015.cnblogs.com/blog/1044869/201705/1044869-20170516110529135-1479973964.png)

Threads_connected---打开的连接数

Threads_running---这个数值指的是激活的连接数，这个数值一般远低于connected数值

如果最大连接数的值太小可以根据实际情况进行修改，一般修改为1000即可，设置方法有两种：

1.临时设置，重启服务后将失效

　　　　![img](https://images2015.cnblogs.com/blog/1044869/201705/1044869-20170516111323775-1382700176.png)

2.修改数据库配置文件，在/etc/my.cnf 文件的[mysqld]下增减一行：max_connections = 1000

### 超时控制

mysql存在一项属性“wait_timeout”,默认值为28800秒(8小时)，wait_timeout的值可以设定，但最多只能是2147483，不能再大了。也就是约24.85天 ，可以通过show global variables like 'wait_timeout';命令来查看。

wait_timeout的含义是：一个connection空闲超过8个小时，Mysql将自动断开该connection，通俗的讲就是一个连接在8小时内没有活动，就会自动断开该连接。由于dbcp没有检验该connection是否有效，用其进行数据操作便会出现异常。

如果是由超时控制引起的问题，不建议修改wait_timeout的值，在数据库连接的url的后面加上“&autoReconnect=true&failOverReadOnly=false”即可解决。

### DNS反向解析　　

MySQL数据库收到一个网络连接后，首先拿到对方的IP地址，然后对这个IP地址进行反向DNS解析从而得到这个IP地址对应的主机名。用主机名在权限系统里面进行权限判断。反向DNS解析是耗费时间的，有可能让用户感觉起来很慢。甚至有的时候，反向解析出来的主机名并没有指向这个IP地址，这时候就无法连接成功了。 可以在配置文件里面禁止MySQL进行反向DNS解析，只需在my.cnf的[mysqld]段落中加入如下行即可：

　　　　　　skip-name-resolve (windows与linux下一样的)

#### 表高速缓存

show global status like 'open%tables%';查看打开的表的数量：

　　![img](https://images2015.cnblogs.com/blog/1044869/201705/1044869-20170516113228760-1132120466.png)　　　　　　

open_tables:是当前在缓存中打开表的数量。

opened_tables:是mysql自启动起，打开表的数量。

 当Opened_tables数值非常大，说明cache太小，导致要频繁地open table，可以查看下当前的table_open_cache设置：

show variables like 'table_open_cache';  查看缓存的上限值

　　![img](https://images2015.cnblogs.com/blog/1044869/201705/1044869-20170516113246932-1354351871.png)

设置table_open_cache的值有两种方式(如果是4G左右内存的服务器,建议设为2048):

1.临时设置，重启服务后将失效

set global table_open_cache=2048;

2.修改数据库配置文件

在/etc/my.cnf 文件的[mysqld]下增减一行：table_open_cache = 2048

### 慢查询日志

记录的慢查询日志的目的是确认是否是由于某些语句执行缓慢而导致的服务器响应慢。

# 如何保证网络传输的安全性

三个方面：

1. **发送方鉴别**：确保接收到的数据，确实是由我们认为的那个人（或主机）发送来的，而不是其他人以虚假身份发送的；
2. **报文完整性**：确保我们接收到的报文就是发送方发送的初始报文，而没有被第三方进行篡改；
3. **数据机密性**：确保报文即使被其他人截获，也无法读出其中的信息，也就是要对数据加密；

## 数据机密性

### 非对称加密

1. 发送方获取接受方的公钥，使用公钥对需要发送的数据进行加密，然后发送；
2. 接受方接收到后，使用自己的私钥进行解密，解析出数据；

### 非对称加密 + 对称加密（多次传输）

1. 发送方随机生成一个密钥，然后获取接受方的公钥，使用公钥加密这个密钥，发送给接受方；
2. 接收方接收到加密的密钥后，使用自己的私钥解析出密钥，此时双方就完成了密钥同步；
3. 之后双方发送的所有数据，都可以使用这个密钥进行加密解密；

### 非对称加密 + 对称加密（单次传输）

如果发送方只是需要向接收方发送一次数据，那先进行一次密钥同步可能有些浪费时间，可以使用如下方案解决：

1. 发送方随机生成一个密钥，然后使用这个密钥对数据进行加密；
2. 发送方使用接收方的公钥对数据密钥进行加密，然后将加密的数据和加密的密钥发送；
3. 接收方首先使用自己的私钥解析出密钥，然后使用解析出的密钥将数据解析出来；

## 同时解决发送方鉴别与报文完整性

1. 发送方使用一个`hash`算法（如`MD5`、`SHA-1`），计算需要发送的数据的`hash`值；
2. 使用自己的私钥，对计算出的`hash`值进行加密；
3. 将原始数据和加密后的`hash`值发送到接收方；
4. 接收方使用发送方的公钥解析出加密后的`hash`值；
5. 使用与发送方相同的`hash`算法，计算接收到的数据的`hash`值，与解析出的`hash`值进行比较；
6. 若这两个`hash`值一致，表示这个数据并没有被篡改；

## 同时解决三个问题的方案

1. 首先，对数据进行处理，也就是计算`hash`，然后使用自己的私钥加密`hash`；
2. 然后，将第一步计算出的`hash`与原始数据组合，使用非对称加密 + 对称加密的方式，进行加密，加密之后再进行发送，保证数据的隐秘性；
3. 接收方接收到数据后，对数据解密，得到原始数据和加密后的`hash`；
4. 完成发送方鉴别以及数据完整性校验；

## 解决发送方鉴别的其他方案

假设接收方和发送方有一个共享的密钥，则可以使用以下方式进行身份鉴别：

1. 发送方向接收方发送自己的身份，比如发送一个“我是xxx”；
2. 接收方为了验证不是其他人发送的虚假数据，向发送方发送一个随机数，这个随机数短时间内不会重复；
3. 发送方使用它们共享的密钥，对这个随机数加密后发回接收方；
4. 接收方接收后，使用密钥解密，如果确实是自己之前发送出去的随机数，即可确认对方身份；

## 解决数据完整性的其他方案

假设发送方和接收方有一个共享的密钥，则可以使用如下步骤保证数据完整性：

1. 发送方将原始数据与密钥拼接，然后计算拼接后的`hash`值，将这个`hash`值与原始数据一同发送；
2. 接收方接收到后，同样将原始数据和密钥拼接，并计算`hash`值，然后与发来的`hash`值比较；
3. 若`hash`值一致，可以保证这个数据没有修改，否则就是被篡改的数据；

# 路由找最短路径

因特网是全球性的网络，因特网内部又划分为多个子网，专业名称为**自治系统**（简称AS），自治系统内部有很多路由器，自治系统之间也有很多路由器。

路由器的主要工作是**为经过路由器的数据包找到一条最佳传输路径**，并将该数据有效地传送到目的站点。

路由器之间需要交换路由信息，如果每个路由器都按之间的想法去做事情，就会乱套了，所以每个路由器都得遵循协议，分别是**内部网关协议**(IGP)和**边界网关协议**（BGP）（以前用的外部网关协议（EGP）现已过时，现在用的是边界网关协议），统称为路由选择协议。

路由选择协议的作用到底是**交换路由信息**与**寻找最短路径**。

内部网关协议包括基于距离向量的路由选择协议（RIP）、链路状态路由协议（OSPF）。

**RIP的原理是怎样的？**

1. 仅和相邻路由交换信息
2. 路由器交换的信息是当前本路由器所知道的全部信息，即自己的路由表。也就是说，交换的信息是：“我到本自治系统中所有网络的（最短）距离，以及到那个网络应经过的下一跳路由器。”
3. 按固定时间间隔交换路由信息，例如，每隔30秒。然后路由器根据收到的路由信息更新路由表。

RIP使用何种算法寻找最短路径？

距离向量算法

什么情况下选择是用RIP协议？

算法简单，适用于相对较小的自治系统。

**OSPF原理是什么？**

1. 向本自治系统中所有路由器发送信息。
2. 发送的信息就是与本路由器相邻的所有路由器的链路状态（所谓链路就是从一个节点到相邻节点的一段物理线路），但这只是路由器所知道的部分信息。
3. 只有在链路状态发生变化时，路由器才向所有路由器用洪泛法发送此信息。

OSPF协议使用何种算法寻找最短路径？

链路状态路由算法Dijkstra

什么情况下选择是用OSPF协议？

OSPF协议适用于大网络。

**外部网关协议就只有BGP协议**



